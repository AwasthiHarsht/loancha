{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Cyw8mrnz0_y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import tempfile\n",
        "import logging\n",
        "import datetime\n",
        "import json\n",
        "from typing import Tuple, Dict, Any, Optional, List\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Optional ML libs (used for retrain_from_logs)\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    lgb = None\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# transformers (loaded lazily)\n",
        "from transformers import pipeline as hf_pipeline\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"chatbot_pipeline\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODEL_PATH = os.environ.get(\"MODEL_PATH\", \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\")\n",
        "DB_URL = os.environ.get(\"DB_URL\", \"postgresql://username:password@localhost:5432/chatbot_db\")\n",
        "RETRAIN_THRESHOLD = int(os.environ.get(\"RETRAIN_THRESHOLD\", \"1000\"))\n",
        "DEFAULT_SENTIMENT_MODEL = os.environ.get(\"DEFAULT_SENTIMENT_MODEL\", \"j-hartmann/emotion-english-distilroberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfk7EUA10F0G",
        "outputId": "ffb5e3a2-a35b-48da-8771-a75577e8f2ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACTIONS = [\n",
        "    \"no_contact\",\n",
        "    \"soft_reminder\",\n",
        "    \"reminder_payment\",\n",
        "    \"offer_plan_low\",\n",
        "    \"offer_plan_high\",\n",
        "    \"escalate_call\",\n",
        "    \"senior_agent\",\n",
        "    \"legal_notice\"\n",
        "]\n",
        "EPSILON = float(os.environ.get(\"POLICY_EPSILON\", \"0.05\"))\n",
        "POLICY_REFERENCE = os.environ.get(\"POLICY_REFERENCE\", \"heuristic_v1\")\n",
        "\n",
        "_model = None\n",
        "MODEL_FEATURES: List[str] = []\n",
        "CATEGORICAL_FEATURES: List[str] = []\n"
      ],
      "metadata": {
        "id": "oouRxOOm1acT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lazy HF pipelines\n",
        "_HF_PIPELINES = {\"sentiment\": None, \"zero_shot\": None, \"llm\": None}\n",
        "\n",
        "# Intent classifier objects\n",
        "INTENT_VECT = None\n",
        "INTENT_CLF = None\n",
        "INTENT_LABELS = None\n",
        "\n",
        "LLM_MODEL_NAME = None  # set to a model id to enable LLM templating\n",
        "\n",
        "def load_model(path: str = MODEL_PATH) -> Tuple[Any, list, list]:\n",
        "    global _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Model file not found at {path}\")\n",
        "    data = joblib.load(path)\n",
        "    _model = data.get(\"model\")\n",
        "    MODEL_FEATURES = data.get(\"features\", [])\n",
        "    CATEGORICAL_FEATURES = data.get(\"categorical\", []) or []\n",
        "    logger.info(f\"Loaded model from {path}. Feature count: {len(MODEL_FEATURES)}\")\n",
        "    return _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "\n",
        "def get_engine(db_url: str = DB_URL):\n",
        "    return create_engine(db_url, future=True)\n"
      ],
      "metadata": {
        "id": "O2ylzTQX1b8p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- HF PIPELINE HELPERS (lazy) ----------\n",
        "def get_sentiment_pipeline(model_name: str = DEFAULT_SENTIMENT_MODEL):\n",
        "    if _HF_PIPELINES[\"sentiment\"] is None:\n",
        "        logger.info(f\"Loading emotion pipeline ({model_name})\")\n",
        "        # For emotion model, return all scores for each emotion class\n",
        "        _HF_PIPELINES[\"sentiment\"] = hf_pipeline(\n",
        "            \"text-classification\",\n",
        "            model=model_name,\n",
        "            return_all_scores=True\n",
        "        )\n",
        "    return _HF_PIPELINES[\"sentiment\"]\n",
        "\n",
        "def get_zero_shot_pipeline():\n",
        "    if _HF_PIPELINES[\"zero_shot\"] is None:\n",
        "        logger.info(\"Loading zero-shot classification pipeline (facebook/bart-large-mnli)\")\n",
        "        _HF_PIPELINES[\"zero_shot\"] = hf_pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "    return _HF_PIPELINES[\"zero_shot\"]\n",
        "\n",
        "def get_llm_pipeline(model_name: str):\n",
        "    if model_name is None:\n",
        "        return None\n",
        "    if _HF_PIPELINES[\"llm\"] is None or LLM_MODEL_NAME != model_name:\n",
        "        logger.info(f\"Loading LLM pipeline: {model_name}\")\n",
        "        _HF_PIPELINES[\"llm\"] = hf_pipeline(\"text-generation\", model=model_name)\n",
        "    return _HF_PIPELINES[\"llm\"]"
      ],
      "metadata": {
        "id": "QtVX9pWq1mNG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- SENTIMENT (EMOTION) ANALYZER ----------\n",
        "def analyze_sentiment(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Return top emotion label and its confidence score (0..1).\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return \"neutral\", 0.0\n",
        "    try:\n",
        "        sentiment = get_sentiment_pipeline()\n",
        "        results = sentiment(text[:512])[0]  # List of dicts: [{'label':..., 'score':...}, ...]\n",
        "        top_emotion = max(results, key=lambda x: x['score'])\n",
        "        label = top_emotion['label'].lower()  # e.g. \"joy\", \"anger\", \"sadness\"\n",
        "        score = float(top_emotion['score'])\n",
        "        return label, score\n",
        "    except Exception:\n",
        "        logger.exception(\"Emotion analysis failed; returning neutral\")\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "def detect_persona(sentiment_label: str, message: str, user_features: Optional[dict] = None) -> str:\n",
        "    \"\"\"\n",
        "    Heuristic-based persona detection.\n",
        "    \"\"\"\n",
        "    msg = (message or \"\").strip()\n",
        "    user_features = user_features or {}\n",
        "    missed = int(user_features.get(\"MissedPayments\", 0) or 0)\n",
        "    response_time = user_features.get(\"ResponseTimeHours\", None)\n",
        "\n",
        "    # Adapted heuristics using emotion labels instead of simple POSITIVE/NEGATIVE\n",
        "    if sentiment_label in (\"joy\", \"love\", \"surprise\") and missed <= 1:\n",
        "        return \"cooperative\"\n",
        "    if sentiment_label in (\"anger\", \"fear\", \"sadness\") and (\"!\" in msg or len(msg) < 40):\n",
        "        return \"aggressive\"\n",
        "    if \"?\" in msg or \"don't understand\" in msg.lower() or \"how\" in msg.lower():\n",
        "        return \"confused\"\n",
        "    if missed >= 2 or (response_time is not None and response_time > 48):\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n"
      ],
      "metadata": {
        "id": "GFVx7zLl1nzx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- STRATEGY RECOMMENDATION (legacy/helper mapping) ----------\n",
        "ACTION_TO_STRATEGY = {\n",
        "    \"no_contact\": {\"code\": \"monitor\", \"description\": \"Continue monitoring.\"},\n",
        "    \"soft_reminder\": {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app/email.\"},\n",
        "    \"reminder_payment\": {\"code\": \"reminder\", \"description\": \"SMS + payment link.\"},\n",
        "    \"offer_plan_low\": {\"code\": \"offer_plan_low\", \"description\": \"Offer low-leniency repayment plan.\"},\n",
        "    \"offer_plan_high\": {\"code\": \"offer_plan_high\", \"description\": \"Offer high-leniency plan with discount.\"},\n",
        "    \"escalate_call\": {\"code\": \"escalate_call\", \"description\": \"Schedule agent call.\"},\n",
        "    \"senior_agent\": {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent.\"},\n",
        "    \"legal_notice\": {\"code\": \"legal_notice\", \"description\": \"Initiate legal review / notice (guarded).\"}\n",
        "}\n",
        "\n",
        "def recommend_strategy(risk_score: float, persona: str, sentiment_label: str) -> Dict[str, str]:\n",
        "    \"\"\"Legacy function retained for backwards compatibility but not used for policy sampling.\"\"\"\n",
        "    if risk_score >= 0.8:\n",
        "        if persona == \"cooperative\":\n",
        "            return {\"code\": \"offer_plan_high\", \"description\": \"Offer structured repayment plan with possible small discount.\"}\n",
        "        elif persona == \"evasive\":\n",
        "            return {\"code\": \"escalate_call\", \"description\": \"Schedule personalized call and frequent reminders.\"}\n",
        "        elif persona == \"aggressive\":\n",
        "            return {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent for sensitive handling.\"}\n",
        "        else:\n",
        "            return {\"code\": \"contact_high\", \"description\": \"Immediate outreach via call and SMS.\"}\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        if sentiment_label in (\"anger\", \"fear\", \"sadness\"):\n",
        "            return {\"code\": \"empathetic_reminder\", \"description\": \"Send empathetic SMS + email with options.\"}\n",
        "        else:\n",
        "            return {\"code\": \"reminder\", \"description\": \"Send reminder SMS + email with payment link.\"}\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        return {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app notification and email.\"}\n",
        "    else:\n",
        "        return {\"code\": \"monitor\", \"description\": \"No immediate action — continue monitoring.\"}\n",
        "\n",
        "# ---------- PHASE-2: Policy / Action Probabilities & Sampling ----------\n",
        "from math import exp\n",
        "\n",
        "def score_to_action_probs(risk_score: float, persona: str, profile: dict) -> Dict[str, Any]:\n",
        "    logits = {a: 0.0 for a in ACTIONS}\n",
        "\n",
        "    if risk_score >= 0.8:\n",
        "        logits.update({\n",
        "            \"offer_plan_high\": 3.0 if persona == \"cooperative\" else 1.0,\n",
        "            \"escalate_call\": 2.0 if persona in (\"evasive\", \"neutral\") else 0.5,\n",
        "            \"senior_agent\": 2.5 if persona == \"aggressive\" else 0.1,\n",
        "            \"legal_notice\": 0.5\n",
        "        })\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        logits.update({\n",
        "            \"reminder_payment\": 2.5,\n",
        "            \"offer_plan_low\": 1.8 if persona == \"cooperative\" else 0.6,\n",
        "            \"escalate_call\": 0.8 if persona == \"evasive\" else 0.2\n",
        "        })\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        logits.update({\"soft_reminder\": 2.0, \"reminder_payment\": 0.5})\n",
        "    else:\n",
        "        logits.update({\"no_contact\": 2.0, \"soft_reminder\": 0.5})\n",
        "\n",
        "    if persona == \"confused\":\n",
        "        logits[\"offer_plan_low\"] += 0.5\n",
        "        logits[\"reminder_payment\"] += 0.5\n",
        "    if persona == \"aggressive\":\n",
        "        logits[\"senior_agent\"] += 1.0\n",
        "        logits[\"offer_plan_high\"] -= 0.5\n",
        "    if persona == \"evasive\":\n",
        "        logits[\"escalate_call\"] += 1.0\n",
        "\n",
        "    missed = int(profile.get(\"MissedPayments\", 0) or 0)\n",
        "    if missed < 3:\n",
        "        logits[\"legal_notice\"] = -999.0\n",
        "\n",
        "    vals = list(logits.values())\n",
        "    maxv = max(vals)\n",
        "    exp_vals = [exp(v - maxv) for v in vals]\n",
        "    s = sum(exp_vals)\n",
        "    probs = [v / s for v in exp_vals]\n",
        "    return {\"probs\": probs, \"policy_reason\": f\"heuristic_risk:{risk_score:.2f}_persona:{persona}\", \"base_scores\": logits}\n",
        "\n",
        "def sample_action(probs: List[float], epsilon: float = EPSILON) -> Tuple[str, float, List[float]]:\n",
        "    probs = np.array(probs, dtype=float)\n",
        "    probs = probs / probs.sum()\n",
        "\n",
        "    if np.random.rand() < epsilon:\n",
        "        final_probs = np.ones_like(probs) / len(probs)\n",
        "    else:\n",
        "        final_probs = probs\n",
        "\n",
        "    action_idx = int(np.random.choice(np.arange(len(final_probs)), p=final_probs))\n",
        "    action = ACTIONS[action_idx]\n",
        "    propensity = float(final_probs[action_idx])\n",
        "    return action, propensity, final_probs.tolist()"
      ],
      "metadata": {
        "id": "NNuhCSUo1yC5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Persona-Adaptive Chatbot Loop ===\n",
        "import random\n",
        "\n",
        "# Templates for persona + sentiment tone adaptation\n",
        "# RESPONSE_TEMPLATES = {\n",
        "#     \"cooperative\": {\n",
        "#         \"POSITIVE\": [\n",
        "#             \"Glad to hear from you! Let's work out a suitable repayment plan together.\",\n",
        "#             \"That's great. We can arrange something that works for both of us.\"\n",
        "#         ],\n",
        "#         \"NEGATIVE\": [\n",
        "#             \"I understand this might be stressful. We can discuss options to ease the process.\",\n",
        "#             \"I hear your concerns. Let's explore how we can make this manageable.\"\n",
        "#         ],\n",
        "#         \"NEUTRAL\": [\n",
        "#             \"Thanks for your update. Could we discuss a date for the repayment?\",\n",
        "#             \"Alright, let's finalize the details for your payment.\"\n",
        "#         ]\n",
        "#     },\n",
        "#     \"evasive\": {\n",
        "#         \"POSITIVE\": [\n",
        "#             \"It's important we finalize your repayment plan soon to avoid penalties.\",\n",
        "#             \"I'm happy you're positive. Let's lock in a payment date today.\"\n",
        "#         ],\n",
        "#         \"NEGATIVE\": [\n",
        "#             \"I understand, but delaying further could increase charges.\",\n",
        "#             \"It's best we address this now before the situation escalates.\"\n",
        "#         ],\n",
        "#         \"NEUTRAL\": [\n",
        "#             \"Please confirm when you can make the payment.\",\n",
        "#             \"We need your confirmation to proceed with your repayment plan.\"\n",
        "#         ]\n",
        "#     },\n",
        "#     \"aggressive\": {\n",
        "#         \"POSITIVE\": [\n",
        "#             \"I appreciate your willingness to cooperate. Let's move forward constructively.\",\n",
        "#             \"That's good to hear. Let's set a repayment date.\"\n",
        "#         ],\n",
        "#         \"NEGATIVE\": [\n",
        "#             \"I understand you're upset. My goal is to help you avoid penalties.\",\n",
        "#             \"We can find a resolution if we work together.\"\n",
        "#         ],\n",
        "#         \"NEUTRAL\": [\n",
        "#             \"Let's focus on finding a solution to your repayment.\",\n",
        "#             \"Could we talk about your repayment schedule?\"\n",
        "#         ]\n",
        "#     },\n",
        "#     \"confused\": {\n",
        "#         \"POSITIVE\": [\n",
        "#             \"I'm glad you're feeling positive. I can clarify any doubts you have.\",\n",
        "#             \"Great! Let me explain the next steps clearly.\"\n",
        "#         ],\n",
        "#         \"NEGATIVE\": [\n",
        "#             \"I understand things might be unclear. Let me walk you through your loan details.\",\n",
        "#             \"Let's go step-by-step so you understand the repayment process.\"\n",
        "#         ],\n",
        "#         \"NEUTRAL\": [\n",
        "#             \"Do you have any questions about your repayment schedule?\",\n",
        "#             \"Let me explain how the repayment process works.\"\n",
        "#         ]\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# def chatbot_loop():\n",
        "#     print(\"Loan Recovery Chatbot (type 'exit' to quit)\")\n",
        "#     while True:\n",
        "#         user_msg = input(\"\\nCustomer: \")\n",
        "#         if user_msg.lower() == \"exit\":\n",
        "#             print(\"Chatbot: Thank you for your time. Goodbye!\")\n",
        "#             break\n",
        "\n",
        "#         # Example features for demo (replace with actual customer features)\n",
        "#         features = {\n",
        "#             \"MissedPayments\": random.randint(0, 3),\n",
        "#             \"ResponseTimeHours\": random.randint(1, 72)\n",
        "#         }\n",
        "#         risk_score = random.uniform(0, 1)\n",
        "\n",
        "#         # Step 1: Sentiment Analysis\n",
        "#         sentiment_label, _ = analyze_sentiment(user_msg)\n",
        "\n",
        "#         # Step 2: Persona Detection\n",
        "#         persona = detect_persona(sentiment_label, user_msg, features)\n",
        "\n",
        "#         # Step 3: Strategy Recommendation\n",
        "#         strategy = recommend_strategy(risk_score, persona, sentiment_label)\n",
        "\n",
        "#         # Step 4: Select chatbot response\n",
        "#         response_list = RESPONSE_TEMPLATES.get(persona, {}).get(sentiment_label, [])\n",
        "#         if response_list:\n",
        "#             reply = random.choice(response_list)\n",
        "#         else:\n",
        "#             reply = \"Let's discuss your repayment plan.\"\n",
        "\n",
        "#         print(f\"Chatbot ({persona}, {sentiment_label}): {reply}\")\n",
        "#         print(f\"💡 Suggested Recovery Strategy: {strategy['description']} (Risk Score: {risk_score:.2f})\")\n",
        "\n",
        "# Run chatbot loop\n",
        "# chatbot_loop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "5ZH-mDo50UKl",
        "outputId": "a4e0a4b6-14eb-42be-96e1-ae85b7fe11ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'RESPONSE_TEMPLATES = {\\n    \"cooperative\": {\\n        \"POSITIVE\": [\\n            \"Glad to hear from you! Let\\'s work out a suitable repayment plan together.\",\\n            \"That\\'s great. We can arrange something that works for both of us.\"\\n        ],\\n        \"NEGATIVE\": [\\n            \"I understand this might be stressful. We can discuss options to ease the process.\",\\n            \"I hear your concerns. Let\\'s explore how we can make this manageable.\"\\n        ],\\n        \"NEUTRAL\": [\\n            \"Thanks for your update. Could we discuss a date for the repayment?\",\\n            \"Alright, let\\'s finalize the details for your payment.\"\\n        ]\\n    },\\n    \"evasive\": {\\n        \"POSITIVE\": [\\n            \"It\\'s important we finalize your repayment plan soon to avoid penalties.\",\\n            \"I\\'m happy you\\'re positive. Let\\'s lock in a payment date today.\"\\n        ],\\n        \"NEGATIVE\": [\\n            \"I understand, but delaying further could increase charges.\",\\n            \"It\\'s best we address this now before the situation escalates.\"\\n        ],\\n        \"NEUTRAL\": [\\n            \"Please confirm when you can make the payment.\",\\n            \"We need your confirmation to proceed with your repayment plan.\"\\n        ]\\n    },\\n    \"aggressive\": {\\n        \"POSITIVE\": [\\n            \"I appreciate your willingness to cooperate. Let\\'s move forward constructively.\",\\n            \"That\\'s good to hear. Let\\'s set a repayment date.\"\\n        ],\\n        \"NEGATIVE\": [\\n            \"I understand you\\'re upset. My goal is to help you avoid penalties.\",\\n            \"We can find a resolution if we work together.\"\\n        ],\\n        \"NEUTRAL\": [\\n            \"Let\\'s focus on finding a solution to your repayment.\",\\n            \"Could we talk about your repayment schedule?\"\\n        ]\\n    },\\n    \"confused\": {\\n        \"POSITIVE\": [\\n            \"I\\'m glad you\\'re feeling positive. I can clarify any doubts you have.\",\\n            \"Great! Let me explain the next steps clearly.\"\\n        ],\\n        \"NEGATIVE\": [\\n            \"I understand things might be unclear. Let me walk you through your loan details.\",\\n            \"Let\\'s go step-by-step so you understand the repayment process.\"\\n        ],\\n        \"NEUTRAL\": [\\n            \"Do you have any questions about your repayment schedule?\",\\n            \"Let me explain how the repayment process works.\"\\n        ]\\n    }\\n}\\n\\ndef chatbot_loop():\\n    print(\"Loan Recovery Chatbot (type \\'exit\\' to quit)\")\\n    while True:\\n        user_msg = input(\"\\nCustomer: \")\\n        if user_msg.lower() == \"exit\":\\n            print(\"Chatbot: Thank you for your time. Goodbye!\")\\n            break\\n\\n        # Example features for demo (replace with actual customer features)\\n        features = {\\n            \"MissedPayments\": random.randint(0, 3),\\n            \"ResponseTimeHours\": random.randint(1, 72)\\n        }\\n        risk_score = random.uniform(0, 1)\\n\\n        # Step 1: Sentiment Analysis\\n        sentiment_label, _ = analyze_sentiment(user_msg)\\n\\n        # Step 2: Persona Detection\\n        persona = detect_persona(sentiment_label, user_msg, features)\\n\\n        # Step 3: Strategy Recommendation\\n        strategy = recommend_strategy(risk_score, persona, sentiment_label)\\n\\n        # Step 4: Select chatbot response\\n        response_list = RESPONSE_TEMPLATES.get(persona, {}).get(sentiment_label, [])\\n        if response_list:\\n            reply = random.choice(response_list)\\n        else:\\n            reply = \"Let\\'s discuss your repayment plan.\"\\n\\n        print(f\"Chatbot ({persona}, {sentiment_label}): {reply}\")\\n        print(f\"💡 Suggested Recovery Strategy: {strategy[\\'description\\']} (Risk Score: {risk_score:.2f})\")\\n\\n# Run chatbot loop\\nchatbot_loop()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "from sqlalchemy.engine import Engine\n"
      ],
      "metadata": {
        "id": "rDtfy-ZJ0xOI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "log = logging.getLogger(\"persona_chatbot_db\")\n",
        "\n",
        "# ---------- Envs / Paths ----------\n",
        "DB_URL = os.environ.get(\"DB_URL\", \"postgresql://username:password@localhost:5432/chatbot_db\")\n",
        "MODEL_PATH = os.environ.get(\"MODEL_PATH\", \"./loan_default_predictor.pkl\")\n",
        "DEFAULT_SENTIMENT_MODEL = os.environ.get(\"DEFAULT_SENTIMENT_MODEL\", \"distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "uHt5X2Qv9O5O"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Optional transformers ----------\n",
        "try:\n",
        "    from transformers import pipeline as hf_pipeline\n",
        "except Exception:\n",
        "    hf_pipeline = None\n",
        "\n",
        "# ---------- Risk model (optional) ----------\n",
        "_model = None\n",
        "MODEL_FEATURES: List[str] = []\n",
        "CATEGORICAL_FEATURES: List[str] = []\n",
        "\n",
        "def load_risk_model(path: str = MODEL_PATH):\n",
        "    global _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "    if not os.path.exists(path):\n",
        "        log.warning(\"Risk model not found at %s; will use heuristic risk.\", path)\n",
        "        return None\n",
        "    try:\n",
        "        data = joblib.load(path)\n",
        "        _model = data.get(\"model\", None)\n",
        "        MODEL_FEATURES[:] = data.get(\"features\", []) or []\n",
        "        CATEGORICAL_FEATURES[:] = data.get(\"categorical\", []) or []\n",
        "        log.info(\"Loaded risk model. Features: %d; Categorical: %d\", len(MODEL_FEATURES), len(CATEGORICAL_FEATURES))\n",
        "        return _model\n",
        "    except Exception as e:\n",
        "        log.exception(\"Failed loading risk model: %s\", e)\n",
        "        return None"
      ],
      "metadata": {
        "id": "nt6ggiYGB3qk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_risk(state: Dict[str, Any]) -> float:\n",
        "    \"\"\"Predict risk with model if available, else heuristic.\n",
        "    Returns a probability between 0 and 1.\"\"\"\n",
        "    if _model is not None and MODEL_FEATURES:\n",
        "        try:\n",
        "            row = {k: state.get(k, None) for k in MODEL_FEATURES}\n",
        "            X = pd.DataFrame([row])\n",
        "            # Basic type fixes\n",
        "            for c in CATEGORICAL_FEATURES:\n",
        "                if c in X:\n",
        "                    X[c] = X[c].astype(\"category\")\n",
        "            # Predict proba if available\n",
        "            if hasattr(_model, \"predict_proba\"):\n",
        "                proba = float(_model.predict_proba(X)[:, 1][0])\n",
        "            else:\n",
        "                pred = float(_model.predict(X)[0])\n",
        "                proba = min(max(pred, 0.0), 1.0)\n",
        "            return float(proba)\n",
        "        except Exception as e:\n",
        "            log.warning(\"Model prediction failed (%s); falling back to heuristic.\", e)\n",
        "    # Heuristic: heavier weight to MissedPayments and DelaysDays; light to negative sentiment\n",
        "    missed = float(state.get(\"MissedPayments\", 0) or 0)\n",
        "    delays = float(state.get(\"DelaysDays\", 0) or 0)\n",
        "    sent = float(state.get(\"SentimentScore\", 0.0) or 0.0)  # -1..1\n",
        "    base = min(1.0, (missed / 4.0) + (delays / 120.0))\n",
        "    penalty = 0.15 if sent < -0.3 else (0.05 if sent < 0 else 0.0)\n",
        "    proba = max(0.0, min(1.0, base + penalty))\n",
        "    return float(proba)"
      ],
      "metadata": {
        "id": "r6oSEVfbB8Gr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Sentiment (optional) ----------\n",
        "_sentiment_pipe = None\n",
        "\n",
        "def analyze_sentiment(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Return label (POSITIVE/NEGATIVE/NEUTRAL) and signed score (-1..1).\"\"\"\n",
        "    global _sentiment_pipe\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"NEUTRAL\", 0.0\n",
        "    if hf_pipeline is None:\n",
        "        return \"NEUTRAL\", 0.0\n",
        "    try:\n",
        "        if _sentiment_pipe is None:\n",
        "            _sentiment_pipe = hf_pipeline(\"sentiment-analysis\", model=DEFAULT_SENTIMENT_MODEL)\n",
        "        res = _sentiment_pipe(text[:512])[0]\n",
        "        label = res.get(\"label\", \"NEUTRAL\").upper()\n",
        "        score = float(res.get(\"score\", 0.0))\n",
        "        signed = score if label == \"POSITIVE\" else -score\n",
        "        return label, signed\n",
        "    except Exception:\n",
        "        return \"NEUTRAL\", 0.0"
      ],
      "metadata": {
        "id": "Soik2OQVCATa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Persona detection (LLM zero-shot with heuristic fallback) ----------\n",
        "POSSIBLE_PERSONAS = [\"cooperative\", \"aggressive\", \"confused\", \"evasive\", \"neutral\"]\n",
        "_zero_shot = None\n",
        "\n",
        "NEGATIVE_WORDS = {\"terrible\", \"worst\", \"angry\", \"useless\", \"hate\", \"annoyed\", \"mad\"}\n",
        "EVADE_PATTERNS = [r\"\\bi don't know\\b\", r\"\\bnot sure\\b\", r\"\\blater\\b\", r\"\\bskip\\b\", r\"\\bmaybe\\b\"]\n",
        "\n",
        "def detect_persona_heuristic(user_text: str, sentiment_label: str = \"NEUTRAL\", features: Dict[str, Any] = None) -> str:\n",
        "    txt = (user_text or \"\").lower().strip()\n",
        "    features = features or {}\n",
        "    if sentiment_label == \"POSITIVE\":\n",
        "        return \"cooperative\"\n",
        "    if any(w in txt for w in NEGATIVE_WORDS) or \"!\" in txt:\n",
        "        return \"aggressive\"\n",
        "    if any(re.search(p, txt) for p in EVADE_PATTERNS):\n",
        "        return \"evasive\"\n",
        "    if \"?\" in txt or \"how\" in txt or \"help\" in txt or \"don't understand\" in txt:\n",
        "        return \"confused\"\n",
        "    if (features.get(\"MissedPayments\", 0) or 0) >= 2 or (features.get(\"ResponseTimeHours\", 0) or 0) > 48:\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def detect_persona_llm(user_text: str, features: Dict[str, Any] = None) -> Optional[str]:\n",
        "    global _zero_shot\n",
        "    if hf_pipeline is None:\n",
        "        return None\n",
        "    try:\n",
        "        if _zero_shot is None:\n",
        "            _zero_shot = hf_pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "        context = \"\"\n",
        "        if features:\n",
        "            missed = features.get(\"MissedPayments\", 0)\n",
        "            resp = features.get(\"ResponseTimeHours\", \"N/A\")\n",
        "            context = f\" Missed payments: {missed}; Response time: {resp} hours.\"\n",
        "        res = _zero_shot(\n",
        "            f\"Customer message: {user_text}\\n{context}\",\n",
        "            candidate_labels=POSSIBLE_PERSONAS,\n",
        "            multi_label=False\n",
        "        )\n",
        "        return res[\"labels\"][0]\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def detect_persona(user_text: str, sentiment_label: str, features: Dict[str, Any] = None) -> str:\n",
        "    llm_label = detect_persona_llm(user_text, features)\n",
        "    if llm_label:\n",
        "        return llm_label\n",
        "    return detect_persona_heuristic(user_text, sentiment_label, features)\n"
      ],
      "metadata": {
        "id": "bL7heDlKCIJP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Persona detection (LLM zero-shot with heuristic fallback) ----------\n",
        "POSSIBLE_PERSONAS = [\"cooperative\", \"aggressive\", \"confused\", \"evasive\", \"neutral\"]\n",
        "_zero_shot = None\n",
        "\n",
        "NEGATIVE_WORDS = {\"terrible\", \"worst\", \"angry\", \"useless\", \"hate\", \"annoyed\", \"mad\"}\n",
        "EVADE_PATTERNS = [r\"\\bi don't know\\b\", r\"\\bnot sure\\b\", r\"\\blater\\b\", r\"\\bskip\\b\", r\"\\bmaybe\\b\"]\n",
        "\n",
        "def detect_persona_heuristic(user_text: str, sentiment_label: str = \"NEUTRAL\", features: Dict[str, Any] = None) -> str:\n",
        "    txt = (user_text or \"\").lower().strip()\n",
        "    features = features or {}\n",
        "    if sentiment_label == \"POSITIVE\":\n",
        "        return \"cooperative\"\n",
        "    if any(w in txt for w in NEGATIVE_WORDS) or \"!\" in txt:\n",
        "        return \"aggressive\"\n",
        "    if any(re.search(p, txt) for p in EVADE_PATTERNS):\n",
        "        return \"evasive\"\n",
        "    if \"?\" in txt or \"how\" in txt or \"help\" in txt or \"don't understand\" in txt:\n",
        "        return \"confused\"\n",
        "    if (features.get(\"MissedPayments\", 0) or 0) >= 2 or (features.get(\"ResponseTimeHours\", 0) or 0) > 48:\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "def detect_persona_llm(user_text: str, features: Dict[str, Any] = None) -> Optional[str]:\n",
        "    global _zero_shot\n",
        "    if hf_pipeline is None:\n",
        "        return None\n",
        "    try:\n",
        "        if _zero_shot is None:\n",
        "            _zero_shot = hf_pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "        context = \"\"\n",
        "        if features:\n",
        "            missed = features.get(\"MissedPayments\", 0)\n",
        "            resp = features.get(\"ResponseTimeHours\", \"N/A\")\n",
        "            context = f\" Missed payments: {missed}; Response time: {resp} hours.\"\n",
        "        res = _zero_shot(\n",
        "            f\"Customer message: {user_text}\\n{context}\",\n",
        "            candidate_labels=POSSIBLE_PERSONAS,\n",
        "            multi_label=False\n",
        "        )\n",
        "        return res[\"labels\"][0]\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def detect_persona(user_text: str, sentiment_label: str, features: Dict[str, Any] = None) -> str:\n",
        "    llm_label = detect_persona_llm(user_text, features)\n",
        "    if llm_label:\n",
        "        return llm_label\n",
        "    return detect_persona_heuristic(user_text, sentiment_label, features)\n"
      ],
      "metadata": {
        "id": "evJPXtbvCPWO"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}