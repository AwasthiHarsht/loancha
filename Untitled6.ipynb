{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Cyw8mrnz0_y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import tempfile\n",
        "import logging\n",
        "import datetime\n",
        "import json\n",
        "from typing import Tuple, Dict, Any, Optional, List\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Optional ML libs (used for retrain_from_logs)\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except Exception:\n",
        "    lgb = None\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# transformers (loaded lazily)\n",
        "from transformers import pipeline as hf_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(\"chatbot_pipeline\")"
      ],
      "metadata": {
        "id": "iiZoffRQ0EAk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "MODEL_PATH = os.environ.get(\"MODEL_PATH\", \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\")\n",
        "DB_URL = os.environ.get(\"DB_URL\", \"postgresql://username:password@localhost:5432/chatbot_db\")\n",
        "RETRAIN_THRESHOLD = int(os.environ.get(\"RETRAIN_THRESHOLD\", \"1000\"))\n",
        "DEFAULT_SENTIMENT_MODEL = os.environ.get(\"DEFAULT_SENTIMENT_MODEL\", \"distilbert-base-uncased-finetuned-sst-2-english\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfk7EUA10F0G",
        "outputId": "b4e859b5-e4f8-456c-fde8-4006b5ee23d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACTIONS = [\n",
        "    \"no_contact\",\n",
        "    \"soft_reminder\",\n",
        "    \"reminder_payment\",\n",
        "    \"offer_plan_low\",\n",
        "    \"offer_plan_high\",\n",
        "    \"escalate_call\",\n",
        "    \"senior_agent\",\n",
        "    \"legal_notice\"\n",
        "]\n",
        "EPSILON = float(os.environ.get(\"POLICY_EPSILON\", \"0.05\"))  # 5% random explore\n",
        "POLICY_REFERENCE = os.environ.get(\"POLICY_REFERENCE\", \"heuristic_v1\")"
      ],
      "metadata": {
        "id": "oouRxOOm1acT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_model = None\n",
        "MODEL_FEATURES: List[str] = []\n",
        "CATEGORICAL_FEATURES: List[str] = []\n",
        "\n",
        "# Lazy HF pipelines (avoid downloading at import time)\n",
        "_HF_PIPELINES = {\"sentiment\": None, \"zero_shot\": None, \"llm\": None}\n",
        "\n",
        "# Intent classifier objects\n",
        "INTENT_VECT = None\n",
        "INTENT_CLF = None\n",
        "INTENT_LABELS = None\n",
        "\n",
        "LLM_MODEL_NAME = None  # set to a model id to enable LLM templating"
      ],
      "metadata": {
        "id": "O2ylzTQX1b8p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(path: str = MODEL_PATH) -> Tuple[Any, list, list]:\n",
        "    global _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Model file not found at {path}\")\n",
        "    data = joblib.load(path)\n",
        "    _model = data.get(\"model\")\n",
        "    MODEL_FEATURES = data.get(\"features\", [])\n",
        "    CATEGORICAL_FEATURES = data.get(\"categorical\", []) or []\n",
        "    logger.info(f\"Loaded model from {path}. Feature count: {len(MODEL_FEATURES)}\")\n",
        "    return _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "\n",
        "\n",
        "def get_engine(db_url: str = DB_URL):\n",
        "    return create_engine(db_url, future=True)"
      ],
      "metadata": {
        "id": "QtVX9pWq1mNG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- HF PIPELINE HELPERS (lazy) ----------\n",
        "def get_sentiment_pipeline(model_name: str = DEFAULT_SENTIMENT_MODEL):\n",
        "    if _HF_PIPELINES[\"sentiment\"] is None:\n",
        "        logger.info(f\"Loading sentiment pipeline ({model_name})\")\n",
        "        _HF_PIPELINES[\"sentiment\"] = hf_pipeline(\"sentiment-analysis\", model=model_name)\n",
        "    return _HF_PIPELINES[\"sentiment\"]\n",
        "\n",
        "\n",
        "def get_zero_shot_pipeline():\n",
        "    if _HF_PIPELINES[\"zero_shot\"] is None:\n",
        "        logger.info(\"Loading zero-shot classification pipeline (facebook/bart-large-mnli)\")\n",
        "        _HF_PIPELINES[\"zero_shot\"] = hf_pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "    return _HF_PIPELINES[\"zero_shot\"]\n",
        "\n",
        "\n",
        "def get_llm_pipeline(model_name: str):\n",
        "    if model_name is None:\n",
        "        return None\n",
        "    if _HF_PIPELINES[\"llm\"] is None or LLM_MODEL_NAME != model_name:\n",
        "        logger.info(f\"Loading LLM pipeline: {model_name}\")\n",
        "        _HF_PIPELINES[\"llm\"] = hf_pipeline(\"text-generation\", model=model_name)\n",
        "    return _HF_PIPELINES[\"llm\"]"
      ],
      "metadata": {
        "id": "GFVx7zLl1nzx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ---------- SENTIMENT ANALYZER ----------\n",
        "def analyze_sentiment(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Return label ('POSITIVE'/'NEGATIVE'/'NEUTRAL') and signed score (-1..1).\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return \"NEUTRAL\", 0.0\n",
        "    try:\n",
        "        sentiment = get_sentiment_pipeline()\n",
        "        res = sentiment(text[:512])[0]\n",
        "        label = res.get(\"label\", \"NEUTRAL\").upper()\n",
        "        score = float(res.get(\"score\", 0.0))\n",
        "        signed = score if label == \"POSITIVE\" else -score\n",
        "        return label, signed\n",
        "    except Exception:\n",
        "        logger.exception(\"Sentiment analysis failed; returning neutral\")\n",
        "        return \"NEUTRAL\", 0.0\n"
      ],
      "metadata": {
        "id": "NNuhCSUo1yC5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_persona(sentiment_label: str, message: str, user_features: Optional[dict] = None) -> str:\n",
        "    \"\"\"\n",
        "    Heuristic-based persona detection.\n",
        "    \"\"\"\n",
        "    msg = (message or \"\").strip()\n",
        "    user_features = user_features or {}\n",
        "    missed = int(user_features.get(\"MissedPayments\", 0) or 0)\n",
        "    response_time = user_features.get(\"ResponseTimeHours\", None)\n",
        "\n",
        "    if sentiment_label == \"POSITIVE\" and missed <= 1:\n",
        "        return \"cooperative\"\n",
        "    if sentiment_label == \"NEGATIVE\" and (\"!\" in msg or len(msg) < 40):\n",
        "        return \"aggressive\"\n",
        "    if \"?\" in msg or \"don't understand\" in msg.lower() or \"how\" in msg.lower():\n",
        "        return \"confused\"\n",
        "    if missed >= 2 or (response_time is not None and response_time > 48):\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n"
      ],
      "metadata": {
        "id": "Zvx0dRZQ15KL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #---------- STRATEGY RECOMMENDATION (legacy/helper mapping) ----------\n",
        "# keep as a human-readable fallback mapping (used for UI/logging)\n",
        "ACTION_TO_STRATEGY = {\n",
        "    \"no_contact\": {\"code\": \"monitor\", \"description\": \"Continue monitoring.\"},\n",
        "    \"soft_reminder\": {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app/email.\"},\n",
        "    \"reminder_payment\": {\"code\": \"reminder\", \"description\": \"SMS + payment link.\"},\n",
        "    \"offer_plan_low\": {\"code\": \"offer_plan_low\", \"description\": \"Offer low-leniency repayment plan.\"},\n",
        "    \"offer_plan_high\": {\"code\": \"offer_plan_high\", \"description\": \"Offer high-leniency plan with discount.\"},\n",
        "    \"escalate_call\": {\"code\": \"escalate_call\", \"description\": \"Schedule agent call.\"},\n",
        "    \"senior_agent\": {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent.\"},\n",
        "    \"legal_notice\": {\"code\": \"legal_notice\", \"description\": \"Initiate legal review / notice (guarded).\"}\n",
        "}\n",
        "\n",
        "def recommend_strategy(risk_score: float, persona: str, sentiment_label: str) -> Dict[str, str]:\n",
        "    \"\"\"Legacy function retained for backwards compatibility but not used for policy sampling.\"\"\"\n",
        "    # Keep the original simple mapping for UI & compatibility\n",
        "    if risk_score >= 0.8:\n",
        "        if persona == \"cooperative\":\n",
        "            return {\"code\": \"offer_plan_high\", \"description\": \"Offer structured repayment plan with possible small discount.\"}\n",
        "        elif persona == \"evasive\":\n",
        "            return {\"code\": \"escalate_call\", \"description\": \"Schedule personalized call and frequent reminders.\"}\n",
        "        elif persona == \"aggressive\":\n",
        "            return {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent for sensitive handling.\"}\n",
        "        else:\n",
        "            return {\"code\": \"contact_high\", \"description\": \"Immediate outreach via call and SMS.\"}\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        if sentiment_label == \"NEGATIVE\":\n",
        "            return {\"code\": \"empathetic_reminder\", \"description\": \"Send empathetic SMS + email with options.\"}\n",
        "        else:\n",
        "            return {\"code\": \"reminder\", \"description\": \"Send reminder SMS + email with payment link.\"}\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        return {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app notification and email.\"}\n",
        "    else:\n",
        "        return {\"code\": \"monitor\", \"description\": \"No immediate action — continue monitoring.\"}\n"
      ],
      "metadata": {
        "id": "ZBeH_23E2Flm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- PHASE-2: Policy / Action Probabilities & Sampling ----------\n",
        "from math import exp\n",
        "\n",
        "def score_to_action_probs(risk_score: float, persona: str, profile: dict) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Heuristic mapping of (risk, persona) -> logits -> softmax probs.\n",
        "    Returns:\n",
        "      {\"probs\": [...], \"policy_reason\": str, \"base_scores\": {...}}\n",
        "    \"\"\"\n",
        "    logits = {a: 0.0 for a in ACTIONS}\n",
        "\n",
        "    # Base heuristics (tunable)\n",
        "    if risk_score >= 0.8:\n",
        "        logits.update({\n",
        "            \"offer_plan_high\": 3.0 if persona == \"cooperative\" else 1.0,\n",
        "            \"escalate_call\": 2.0 if persona in (\"evasive\", \"neutral\") else 0.5,\n",
        "            \"senior_agent\": 2.5 if persona == \"aggressive\" else 0.1,\n",
        "            \"legal_notice\": 0.5\n",
        "        })\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        logits.update({\n",
        "            \"reminder_payment\": 2.5,\n",
        "            \"offer_plan_low\": 1.8 if persona == \"cooperative\" else 0.6,\n",
        "            \"escalate_call\": 0.8 if persona == \"evasive\" else 0.2\n",
        "        })\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        logits.update({\"soft_reminder\": 2.0, \"reminder_payment\": 0.5})\n",
        "    else:\n",
        "        logits.update({\"no_contact\": 2.0, \"soft_reminder\": 0.5})\n",
        "\n",
        "    # Persona modifiers\n",
        "    if persona == \"confused\":\n",
        "        logits[\"offer_plan_low\"] += 0.5\n",
        "        logits[\"reminder_payment\"] += 0.5\n",
        "    if persona == \"aggressive\":\n",
        "        logits[\"senior_agent\"] += 1.0\n",
        "        logits[\"offer_plan_high\"] -= 0.5\n",
        "    if persona == \"evasive\":\n",
        "        logits[\"escalate_call\"] += 1.0\n",
        "\n",
        "    # Safety guardrails: remove illegal actions\n",
        "    # Example: enforce a rule that legal_notice requires MissedPayments >= 3\n",
        "    missed = int(profile.get(\"MissedPayments\", 0) or 0)\n",
        "    if missed < 3:\n",
        "        logits[\"legal_notice\"] = -999.0\n",
        "\n",
        "    # Convert logits -> softmax probabilities safely\n",
        "    vals = list(logits.values())\n",
        "    maxv = max(vals)\n",
        "    exp_vals = [exp(v - maxv) for v in vals]  # numerical stability\n",
        "    s = sum(exp_vals)\n",
        "    probs = [v / s for v in exp_vals]\n",
        "    return {\"probs\": probs, \"policy_reason\": f\"heuristic_risk:{risk_score:.2f}_persona:{persona}\", \"base_scores\": logits}\n",
        "\n",
        "\n",
        "def sample_action(probs: List[float], epsilon: float = EPSILON) -> Tuple[str, float, List[float]]:\n",
        "    \"\"\"\n",
        "    Epsilon-greedy with softmax sampling.\n",
        "    Returns (action, propensity, final_probs_used).\n",
        "    \"\"\"\n",
        "    probs = np.array(probs, dtype=float)\n",
        "    probs = probs / probs.sum()\n",
        "\n",
        "    if np.random.rand() < epsilon:\n",
        "        # uniform random exploration\n",
        "        final_probs = np.ones_like(probs) / len(probs)\n",
        "    else:\n",
        "        final_probs = probs\n",
        "\n",
        "    action_idx = int(np.random.choice(np.arange(len(final_probs)), p=final_probs))\n",
        "    action = ACTIONS[action_idx]\n",
        "    propensity = float(final_probs[action_idx])\n",
        "    return action, propensity, final_probs.tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "bPRi3mF72Oh-"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}