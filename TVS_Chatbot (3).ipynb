{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "h_ZnTZ7XoKo4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d9c998-e1a7-4b52-e369-ad45e7828917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/515.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.7/515.7 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Colab / General setup\n",
        "!pip -q install lightgbm shap psycopg2-binary transformers==4.41.2 huggingface_hub==0.33.5\n",
        "\n",
        "import os, re, json, glob, joblib, math, textwrap, datetime as dt\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional, Callable, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import shap\n",
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login(token=\"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\")\n",
        "\n",
        "# --- Search for model in Drive ---\n",
        "model_name = \"loan_default_predictor.pkl\"\n",
        "search_root = \"/content/drive/MyDrive\"\n",
        "model_path = None\n",
        "\n",
        "for root, dirs, files in os.walk(search_root):\n",
        "    if model_name in files:\n",
        "        model_path = os.path.join(root, model_name)\n",
        "        break\n",
        "\n",
        "if model_path:\n",
        "    print(f\"✅ Found model at: {model_path}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"❌ Could not find {model_name} in {search_root}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDLhO26U6pJp",
        "outputId": "6cff5612-f820-4613-aba9-be93768a97ae"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found model at: /content/drive/MyDrive/loan_default_predictor.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_features = [[35, 500000, 250000, 60, 12.0, 2, 30, 1, 3, 12.5, 40, 5, 0, 0.2]]\n",
        "\n",
        "try:\n",
        "    if hasattr(lgb_model, \"predict_proba\"):\n",
        "        risk = float(lgb_model.predict_proba(sample_features)[0][1])\n",
        "    else:\n",
        "        risk = float(lgb_model.predict(sample_features)[0])\n",
        "    print(f\"📊 Sample Risk Prediction: {risk:.3f}\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Prediction error: {e}\")"
      ],
      "metadata": {
        "id": "_sFow6Pa7Hmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c5c17e-0afc-4708-e6fd-e4a54d92afde"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Prediction error: 'dict' object has no attribute 'predict'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6cZoz36hvl-",
        "outputId": "873386c0-9b9d-4d1d-ae48-7fd027733abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Found model at: /content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Model path ---\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\"\n",
        "\n",
        "\n",
        "\n",
        "# --- Check if model file exists ---\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"✅ Found model at: {model_path}\")\n",
        "else:\n",
        "    print(f\"❌ Model file not found. Please check path: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HjEL9kTYihn2"
      },
      "outputs": [],
      "source": [
        "def int_in_range(min_v: int, max_v: int):\n",
        "    def _v(x: str):\n",
        "        x = x.strip()\n",
        "        if not re.fullmatch(r\"-?\\d+\", x):\n",
        "            return False, None, f\"Please enter a whole number between {min_v} and {max_v}.\"\n",
        "        val = int(x)\n",
        "        if not (min_v <= val <= max_v):\n",
        "            return False, None, f\"Value must be between {min_v} and {max_v}.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def float_in_range(min_v: float, max_v: float):\n",
        "    def _v(x: str):\n",
        "        x = x.strip().replace(\",\", \"\")\n",
        "        try:\n",
        "            val = float(x)\n",
        "        except ValueError:\n",
        "            return False, None, f\"Please enter a number between {min_v} and {max_v}.\"\n",
        "        if not (min_v <= val <= max_v):\n",
        "            return False, None, f\"Value must be between {min_v} and {max_v}.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def positive_float():\n",
        "    def _v(x: str):\n",
        "        x = x.strip().replace(\",\", \"\")\n",
        "        try:\n",
        "            val = float(x)\n",
        "        except ValueError:\n",
        "            return False, None, \"Please enter a positive number.\"\n",
        "        if val <= 0:\n",
        "            return False, None, \"Value must be > 0.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def one_of(options: List[str]):\n",
        "    lower_opts = [o.lower() for o in options]\n",
        "    def _v(x: str):\n",
        "        s = x.strip()\n",
        "        if s.lower() not in lower_opts:\n",
        "            return False, None, f\"Please choose one of: {', '.join(options)}.\"\n",
        "        return True, options[lower_opts.index(s.lower())], \"\"\n",
        "    return _v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RHjPiunVisuU"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class FieldSpec:\n",
        "    name: str\n",
        "    prompt: str\n",
        "    validator: Callable[[str], Tuple[bool, Optional[Any], str]]\n",
        "    required: bool = True\n",
        "    depends_on: Optional[Callable[[Dict[str, Any]], bool]] = None\n",
        "\n",
        "def income_optional_if_unemployed_or_student(state: Dict[str, Any]) -> bool:\n",
        "    status = state.get(\"EmploymentStatus\", \"\").lower()\n",
        "    return status not in {\"unemployed\", \"student\"}\n",
        "\n",
        "def partial_payments_if_missed(state: Dict[str, Any]) -> bool:\n",
        "    return state.get(\"MissedPayments\", 0) > 0\n",
        "SCHEMA: List[FieldSpec] = [\n",
        "    FieldSpec(\n",
        "        \"CustomerID\",\n",
        "        \"Enter a unique Customer ID (format: CUST0001):\",\n",
        "        lambda s: (\n",
        "            bool(re.fullmatch(r\"CUST\\d{4}\", s.strip())),\n",
        "            s.strip(),\n",
        "            \"Customer ID must be in the format 'CUST' followed by 4 digits, e.g., CUST0001.\"\n",
        "        )\n",
        "    ),\n",
        "    FieldSpec(\"Age\", \"Please enter your age (18–75):\", int_in_range(18, 75)),\n",
        "    FieldSpec(\"Income\", \"Annual income in INR (e.g., 450000):\", positive_float(),\n",
        "              depends_on=income_optional_if_unemployed_or_student),\n",
        "    FieldSpec(\"Location\", \"Your location (Urban/Suburban/Rural):\", one_of([\"Urban\", \"Suburban\", \"Rural\"])),\n",
        "    FieldSpec(\"EmploymentStatus\", \"Employment status (Self-Employed/Salaried/Student/Unemployed):\",\n",
        "              one_of([\"Self-Employed\", \"Salaried\", \"Student\", \"Unemployed\"])),\n",
        "    FieldSpec(\"LoanAmount\", \"Requested loan amount in INR (must be > 0):\", positive_float()),\n",
        "    FieldSpec(\"TenureMonths\", \"Loan tenure in months (6–360):\", int_in_range(6, 360)),\n",
        "    FieldSpec(\"InterestRate\", \"Annual interest rate in % (1–30):\", float_in_range(1.0, 30.0)),\n",
        "    FieldSpec(\"LoanType\", \"Type of loan (Personal/Auto/Home/Education/Business):\",\n",
        "              one_of([\"Personal\", \"Auto\", \"Home\", \"Education\", \"Business\"])),\n",
        "    FieldSpec(\"MissedPayments\", \"Number of missed payments (0–24):\", int_in_range(0, 24)),\n",
        "    FieldSpec(\"DelaysDays\", \"Total delay in days (0–365):\", int_in_range(0, 365)),\n",
        "    FieldSpec(\"PartialPayments\", \"Number of partial payments (0–24):\", int_in_range(0, 24),\n",
        "              depends_on=partial_payments_if_missed),\n",
        "    FieldSpec(\"InteractionAttempts\", \"Number of contact attempts made (0–50):\", int_in_range(0, 50)),\n",
        "    FieldSpec(\"SentimentScore\", \"Sentiment score from -1 to 1 (e.g., -0.3, 0.7):\", float_in_range(-1.0, 1.0)),\n",
        "    FieldSpec(\"ResponseTimeHours\", \"Average response time in hours (0–240):\", float_in_range(0.0, 240.0)),\n",
        "    FieldSpec(\"AppUsageFrequency\", \"App usage frequency score (0–100):\", float_in_range(0.0, 100.0)),\n",
        "    FieldSpec(\"WebsiteVisits\", \"Number of visits to the loan portal (0–500):\", int_in_range(0, 500)),\n",
        "    FieldSpec(\"Complaints\", \"Number of complaints registered (0–50):\", int_in_range(0, 50)),\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMO_TO_PERSONA = {\n",
        "    \"joy\": \"cooperative\",\n",
        "    \"neutral\": \"evasive\",     # neutral silence can look avoidant\n",
        "    \"surprise\": \"confused\",\n",
        "    \"fear\": \"confused\",\n",
        "    \"sadness\": \"confused\",\n",
        "    \"anger\": \"aggressive\",\n",
        "    \"disgust\": \"aggressive\",\n",
        "}\n",
        "def recommend_strategy(persona: str, risk: float, missed: int):\n",
        "    if risk >= 0.7:\n",
        "        return \"offer_plan_high\" if persona == \"cooperative\" else \\\n",
        "               \"senior_agent\" if persona == \"aggressive\" else \\\n",
        "               \"educational_call\" if persona == \"confused\" else \"escalate_call\"\n",
        "    elif 0.5 <= risk < 0.7:\n",
        "        return \"reminder_payment\" if persona == \"cooperative\" else \\\n",
        "               \"structured_negotiation\" if persona == \"aggressive\" else \\\n",
        "               \"clarification_message\" if persona == \"confused\" else \"follow_up_calls\"\n",
        "    else:\n",
        "        return \"soft_reminder\" if missed > 0 else \"no_contact\"\n",
        "\n",
        "def analyze_and_recommend(lgb, answers: Dict[str, Any]):\n",
        "    feature_cols = [\n",
        "        \"Age\",\"Income\",\"LoanAmount\",\"TenureMonths\",\"InterestRate\",\n",
        "        \"MissedPayments\",\"DelaysDays\",\"PartialPayments\",\"InteractionAttempts\",\n",
        "        \"ResponseTimeHours\",\"AppUsageFrequency\",\"WebsiteVisits\",\"Complaints\",\n",
        "        \"SentimentScore\"\n",
        "    ]\n",
        "    X = [[float(answers.get(col, 0)) for col in feature_cols]]\n",
        "\n",
        "    risk = float(lgb.predict_proba(X)[0][1]) if hasattr(lgb, \"predict_proba\") else float(lgb.predict(X)[0])\n",
        "    target = \"Yes\" if risk >= 0.5 else \"No\"\n",
        "\n",
        "    persona = EMO_TO_PERSONA.get(answers.get(\"SentimentLabel\", \"neutral\").lower(), \"cooperative\")\n",
        "    strategy = recommend_strategy(persona, risk, int(answers.get(\"MissedPayments\", 0)))\n",
        "\n",
        "    answers.update({\"RiskScore\": risk, \"Target\": target, \"Persona\": persona, \"RecommendedStrategy\": strategy})\n",
        "\n",
        "    print(\"\\n--- Analysis Results ---\")\n",
        "    print(f\"📊 Will Miss Next Payment: {target}\")\n",
        "    print(f\"🔢 Risk Score: {risk:.3f}\")\n",
        "    print(f\"🧩 Persona Detected: {persona}\")\n",
        "    print(f\"🎯 Recommended Strategy: {strategy}\")\n",
        "    print(\"-------------------------\\n\")\n",
        "\n",
        "    return answers"
      ],
      "metadata": {
        "id": "38sjpng98H2r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"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\")\n"
      ],
      "metadata": {
        "id": "JbfP6VgpXyb1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Model path ---\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\"\n",
        "\n",
        "\n",
        "\n",
        "# --- Check if model file exists ---\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"✅ Found model at: {model_path}\")\n",
        "else:\n",
        "    print(f\"❌ Model file not found. Please check path: {model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzBkqnllZADp",
        "outputId": "4c0b3298-4d69-4769-fabe-9884093f5c5a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Found model at: /content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "4vrmACs9qU0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736655e4-4bd9-4009-972b-5e8fe99f1a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model found at /content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\n",
            "⏳ Loading emotion model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Emotion model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def load_lgb_model(path: str = model_path):\n",
        "    \"\"\"Load LightGBM model from pkl file in Google Drive\"\"\"\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"❌ Model not found at {path}\")\n",
        "    print(f\"✅ Model found at {path}\")\n",
        "    return joblib.load(path)\n",
        "\n",
        "def load_emotion_model():\n",
        "    \"\"\"Load HuggingFace emotion classification model\"\"\"\n",
        "    print(\"⏳ Loading emotion model...\")\n",
        "    emo_pipe = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "        top_k=1\n",
        "    )\n",
        "    print(\"✅ Emotion model loaded successfully!\")\n",
        "    return emo_pipe\n",
        "\n",
        "# --- Load models once ---\n",
        "lgb_model = load_lgb_model()\n",
        "emotion_pipe = load_emotion_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Main Loop\n",
        "# ----------------------------\n",
        "def main():\n",
        "    print(\"🤖 Welcome to the Loan Collection Persona Chatbot (PostgreSQL Edition)\\n\")\n",
        "\n",
        "    #init_db()\n",
        "    lgb = load_lgb_model\n",
        "    emo_pipe = load_emotion_model()\n",
        "\n",
        "    answers: Dict[str, Any] = {}\n",
        "    persona = \"cooperative\"\n",
        "\n",
        "    for field in SCHEMA:\n",
        "        if field.depends_on and not field.depends_on(answers):\n",
        "            continue\n",
        "        while True:\n",
        "            prompt = style_prompt(field.prompt, persona)\n",
        "            raw = input(prompt + \"\\n> \")\n",
        "            valid, val, err = field.validator(raw)\n",
        "            if valid:\n",
        "                answers[field.name] = val\n",
        "                break\n",
        "            else:\n",
        "                print(style_error(err, persona))\n",
        "\n",
        "    while True:\n",
        "        msg = input(style_prompt(\"Lastly, how do you feel about repayment? (free text)\", persona) + \"\\n> \")\n",
        "        if msg.strip():\n",
        "            emo_result = emo_pipe(msg)[0][0]\n",
        "            answers[\"UserMessage\"] = msg\n",
        "            answers[\"SentimentLabel\"] = emo_result[\"label\"]\n",
        "            answers[\"SentimentScore\"] = normalize_sentiment_score(emo_result[\"label\"], emo_result[\"score\"])\n",
        "            persona = EMO_TO_PERSONA.get(emo_result[\"label\"].lower(), \"cooperative\")\n",
        "            break\n",
        "        else:\n",
        "            print(style_error(\"Message cannot be empty.\", persona))\n",
        "\n",
        "    results = analyze_and_recommend(lgb, answers)\n",
        "    save_to_db(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "hQLHUfxx8O_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c95f13-fc2b-4769-c8dd-f8461f9a1d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Welcome to the Loan Collection Persona Chatbot (PostgreSQL Edition)\n",
            "\n",
            "⏳ Loading emotion model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Emotion model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0dRPV42qb6X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4W-UiptqdeS"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG3SrCTKqkxz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YiaqubJqmP3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDSNOtv5qy7Z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fyeqPNOt1Hc"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTU_W4NAt3Bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827XA8-ct4Zt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wWlJ8-lt7f3"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5JaiDpSt91z"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPtfjBxJt_pj"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R6W36R2ByuAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "IJ6P3R9XuDkl",
        "outputId": "38fcdc29-09be-4b2d-a280-f569fc84d18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "💬 Loan Assistant Chatbot (CLI)\n",
            "==============================\n",
            "\n",
            "❌ Database connection failed: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n",
            "\tIs the server running on that host and accepting TCP/IP connections?\n",
            "connection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n",
            "\tIs the server running on that host and accepting TCP/IP connections?\n",
            "\n",
            "⚠️ Skipping DB init — connection unavailable.\n",
            "ℹ️ [DEBUG] Session already initialized — skipping reset.\n",
            "\n",
            "🤖 Bot: 🙂 What is your age? (18–75)\n",
            "👤 You: 10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-132447811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcli_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-132447811.py\u001b[0m in \u001b[0;36mcli_chatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# process answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"⚠️ {err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}