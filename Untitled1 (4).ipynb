{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_ZnTZ7XoKo4"
      },
      "outputs": [],
      "source": [
        "# Install required packages with fixed versions (CLI version - no streamlit)\n",
        "!pip install -q pyngrok==7.1.0 \\\n",
        "                psycopg2-binary==2.9.9 \\\n",
        "                transformers==4.41.2 \\\n",
        "                torch==2.3.1 \\\n",
        "                joblib==1.4.2 \\\n",
        "                lightgbm==4.3.0 \\\n",
        "                python-dotenv==1.0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CLI/Streamlit Compatibility Layer ---\n",
        "\n",
        "import sys\n",
        "\n",
        "# 1. Detect if Streamlit is running\n",
        "try:\n",
        "    import streamlit as st\n",
        "    USE_STREAMLIT = st._is_running_with_streamlit\n",
        "except:\n",
        "    st = None\n",
        "    USE_STREAMLIT = False\n",
        "\n",
        "# 2. Session/State manager\n",
        "if USE_STREAMLIT:\n",
        "    state = st.session_state\n",
        "else:\n",
        "    class DummyState(dict):\n",
        "        \"\"\"Fallback session state for CLI mode.\"\"\"\n",
        "        def __getattr__(self, key):\n",
        "            return self.get(key)\n",
        "        def __setattr__(self, key, value):\n",
        "            self[key] = value\n",
        "    state = DummyState()\n",
        "\n",
        "# 3. Unified UI wrappers\n",
        "def ui_error(msg):\n",
        "    if USE_STREAMLIT: st.error(msg)\n",
        "    else: print(f\"‚ùå {msg}\")\n",
        "\n",
        "def ui_success(msg):\n",
        "    if USE_STREAMLIT: st.success(msg)\n",
        "    else: print(f\"‚úÖ {msg}\")\n",
        "\n",
        "def ui_info(msg):\n",
        "    if USE_STREAMLIT: st.info(msg)\n",
        "    else: print(f\"‚ÑπÔ∏è {msg}\")\n",
        "\n",
        "def ui_write(msg):\n",
        "    if USE_STREAMLIT: st.write(msg)\n",
        "    else: print(msg)\n",
        "\n",
        "def ui_markdown(msg):\n",
        "    if USE_STREAMLIT: st.markdown(msg)\n",
        "    else: print(msg)\n",
        "\n",
        "def ui_stop():\n",
        "    if USE_STREAMLIT: st.stop()\n",
        "    else: sys.exit(1)\n",
        "\n",
        "print(\"üîß Compatibility patch applied (CLI + Streamlit).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDLhO26U6pJp",
        "outputId": "3ab18200-835f-47d3-870d-3f3c535e6bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Compatibility patch applied (CLI + Streamlit).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSzzoR9uoRB5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "from dotenv import load_dotenv\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import joblib\n",
        "import psycopg2\n",
        "import psycopg2.extras as pgextras\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "\n",
        "# CLI replacement for Streamlit session state\n",
        "session_state = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CLI-safe Streamlit shim ---\n",
        "class DummyStreamlit:\n",
        "    def __init__(self):\n",
        "        self.session_state = session_state\n",
        "\n",
        "    # session state helpers\n",
        "    def success(self, msg): print(f\"[SUCCESS] {msg}\")\n",
        "    def error(self, msg): print(f\"[ERROR] {msg}\")\n",
        "    def warning(self, msg): print(f\"[WARN] {msg}\")\n",
        "    def write(self, msg): print(msg)\n",
        "    def markdown(self, msg): print(msg)\n",
        "    def stop(self):\n",
        "        raise SystemExit(\"Streamlit stop() called in CLI mode\")\n",
        "\n",
        "    def set_page_config(self, **kwargs):\n",
        "        pass  # no-op in CLI\n",
        "\n",
        "# Replace st with dummy\n",
        "st = DummyStreamlit()\n"
      ],
      "metadata": {
        "id": "_sFow6Pa7Hmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6cZoz36hvl-",
        "outputId": "8c1db74a-82dc-4c3e-921e-b507ac179bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Found model at: /content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- Model path ---\n",
        "model_path = \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\"\n",
        "\n",
        "# --- Load environment variables (for DB credentials, etc.) ---\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('/content/drive/MyDrive/Colab Notebooks/.env')\n",
        "\n",
        "# --- Check if model file exists ---\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"‚úÖ Found model at: {model_path}\")\n",
        "else:\n",
        "    print(f\"‚ùå Model file not found. Please check path: {model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjEL9kTYihn2",
        "outputId": "0a421922-523a-41a3-c7ac-b8f353f0a119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded successfully!\n",
            "üì¶ Database config loaded: Chatbot_db@localhost:5432\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Load model with error handling\n",
        "try:\n",
        "    model = joblib.load(model_path)\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Model file not found at {model_path}. Please check the path.\")\n",
        "    model = None\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading model: {e}\")\n",
        "    model = None\n",
        "\n",
        "# ‚úÖ PostgreSQL credentials (from .env or defaults)\n",
        "DB_HOST = os.environ.get(\"PG_HOST\", \"localhost\")\n",
        "DB_PORT = os.environ.get(\"PG_PORT\", \"5432\")\n",
        "DB_NAME = os.environ.get(\"PG_DB\", \"Chatbot_db\")\n",
        "DB_USER = os.environ.get(\"PG_USER\", \"loan_table\")\n",
        "DB_PASS = os.environ.get(\"PG_PASS\", \"root\")\n",
        "\n",
        "print(f\"üì¶ Database config loaded: {DB_NAME}@{DB_HOST}:{DB_PORT}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHjPiunVisuU"
      },
      "outputs": [],
      "source": [
        "def load_lgb_model():\n",
        "    \"\"\"Load the LightGBM model from disk.\"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"‚ùå Model file not found at {model_path}\")\n",
        "    try:\n",
        "        model = joblib.load(model_path)\n",
        "        print(\"‚úÖ LightGBM model loaded successfully!\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"‚ö†Ô∏è Error loading LightGBM model: {e}\")\n",
        "\n",
        "\n",
        "def load_emotion_model():\n",
        "    \"\"\"Load HuggingFace emotion classification pipeline.\"\"\"\n",
        "    print(\"‚è≥ Loading emotion model (this may take some time the first time)...\")\n",
        "    try:\n",
        "        emo_pipe = pipeline(\n",
        "            \"text-classification\",\n",
        "            model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
        "            top_k=1   # `return_all_scores` deprecated ‚Üí use top_k\n",
        "        )\n",
        "        print(\"‚úÖ Emotion model loaded successfully!\")\n",
        "        return emo_pipe\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"‚ö†Ô∏è Error loading emotion model: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_db_connection():\n",
        "    \"\"\"Create and return a PostgreSQL connection.\"\"\"\n",
        "    try:\n",
        "        conn = psycopg2.connect(\n",
        "            host=DB_HOST,\n",
        "            port=DB_PORT,\n",
        "            dbname=DB_NAME,\n",
        "            user=DB_USER,\n",
        "            password=DB_PASS\n",
        "        )\n",
        "        return conn\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Database connection failed: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "38sjpng98H2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vrmACs9qU0D"
      },
      "outputs": [],
      "source": [
        "def init_db():\n",
        "    \"\"\"Initialize database and create table if not exists.\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"‚ö†Ô∏è Skipping DB init ‚Äî connection unavailable.\")\n",
        "        return\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS loan_chat_sessions (\n",
        "            session_id SERIAL PRIMARY KEY,\n",
        "            customerid TEXT,\n",
        "            age INT,\n",
        "            employmentstatus TEXT,\n",
        "            income DOUBLE PRECISION,\n",
        "            location TEXT,\n",
        "            loantype TEXT,\n",
        "            loanamount DOUBLE PRECISION,\n",
        "            tenuremonths INT,\n",
        "            interestrate DOUBLE PRECISION,\n",
        "            missedpayments INT,\n",
        "            delaysdays INT,\n",
        "            partialpayments INT,\n",
        "            interactionattempts INT,\n",
        "            responsetimehours DOUBLE PRECISION,\n",
        "            appusagefrequency DOUBLE PRECISION,\n",
        "            websitevisits INT,\n",
        "            complaints INT,\n",
        "            usermessage TEXT,\n",
        "            sentimentlabel TEXT,\n",
        "            sentimentscore DOUBLE PRECISION,\n",
        "            persona TEXT,\n",
        "            riskscore DOUBLE PRECISION,\n",
        "            target TEXT,\n",
        "            recommendedstrategy TEXT,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        );\n",
        "        \"\"\")\n",
        "        conn.commit()\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "        print(\"‚úÖ Database initialized successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è DB init failed: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_session_to_db(payload: dict):\n",
        "    \"\"\"Save chatbot session details into PostgreSQL.\"\"\"\n",
        "    conn = get_db_connection()\n",
        "    if conn is None:\n",
        "        print(\"‚ö†Ô∏è Skipping save ‚Äî DB unavailable.\")\n",
        "        return\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\"\"\"\n",
        "            INSERT INTO loan_chat_sessions (\n",
        "                customerid, age, employmentstatus, income, location, loantype,\n",
        "                loanamount, tenuremonths, interestrate, missedpayments, delaysdays,\n",
        "                partialpayments, interactionattempts, responsetimehours, appusagefrequency,\n",
        "                websitevisits, complaints, usermessage, sentimentlabel, sentimentscore,\n",
        "                persona, riskscore, target, recommendedstrategy\n",
        "            ) VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
        "        \"\"\", (\n",
        "            payload.get(\"CustomerID\"),\n",
        "            payload.get(\"Age\"),\n",
        "            payload.get(\"EmploymentStatus\"),\n",
        "            payload.get(\"Income\"),\n",
        "            payload.get(\"Location\"),\n",
        "            payload.get(\"LoanType\"),\n",
        "            payload.get(\"LoanAmount\"),\n",
        "            payload.get(\"TenureMonths\"),\n",
        "            payload.get(\"InterestRate\"),\n",
        "            payload.get(\"MissedPayments\"),\n",
        "            payload.get(\"DelaysDays\"),\n",
        "            payload.get(\"PartialPayments\"),\n",
        "            payload.get(\"InteractionAttempts\"),\n",
        "            payload.get(\"ResponseTimeHours\"),\n",
        "            payload.get(\"AppUsageFrequency\"),\n",
        "            payload.get(\"WebsiteVisits\"),\n",
        "            payload.get(\"Complaints\"),\n",
        "            payload.get(\"UserMessage\"),\n",
        "            payload.get(\"SentimentLabel\"),\n",
        "            payload.get(\"SentimentScore\"),\n",
        "            payload.get(\"Persona\"),\n",
        "            payload.get(\"RiskScore\"),\n",
        "            payload.get(\"Target\"),\n",
        "            payload.get(\"RecommendedStrategy\"),\n",
        "        ))\n",
        "        conn.commit()\n",
        "        cur.close()\n",
        "        conn.close()\n",
        "        print(\"üíæ Session saved to PostgreSQL.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to save session: {e}\")\n"
      ],
      "metadata": {
        "id": "hQLHUfxx8O_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0dRPV42qb6X"
      },
      "outputs": [],
      "source": [
        "EMO_TO_PERSONA = {\n",
        "    \"joy\": \"cooperative\",\n",
        "    \"neutral\": \"evasive\",     # neutral silence can look avoidant\n",
        "    \"surprise\": \"confused\",\n",
        "    \"fear\": \"confused\",\n",
        "    \"sadness\": \"confused\",\n",
        "    \"anger\": \"aggressive\",\n",
        "    \"disgust\": \"aggressive\",\n",
        "}\n",
        "\n",
        "TONE_PREFIX = {\n",
        "    \"cooperative\": \"üòä Thanks! \",\n",
        "    \"evasive\": \"üëâ I‚Äôd really appreciate this detail. \",\n",
        "    \"aggressive\": \"‚ö†Ô∏è I get this can be frustrating. \",\n",
        "    \"confused\": \"‚ùì No worries, I‚Äôll guide you. \",\n",
        "}\n",
        "\n",
        "def tone_question(persona: str, q: str) -> str:\n",
        "    \"\"\"Return a persona-adjusted version of the bot‚Äôs question.\"\"\"\n",
        "    prefix = TONE_PREFIX.get(persona, \"üôÇ \")\n",
        "    return f\"{prefix}{q}\"\n",
        "\n",
        "\n",
        "def normalize_sentiment_score(label: str, score: float) -> float:\n",
        "    \"\"\"Normalize raw emotion score into a signed sentiment value.\"\"\"\n",
        "    label = (label or \"\").lower()\n",
        "    try:\n",
        "        val = float(score)\n",
        "    except (TypeError, ValueError):\n",
        "        return 0.0\n",
        "\n",
        "    if label == \"joy\":\n",
        "        return +val\n",
        "    if label in (\"anger\", \"disgust\", \"fear\", \"sadness\"):\n",
        "        return -val\n",
        "    # treat neutral/surprise/unknown as 0\n",
        "    return 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4W-UiptqdeS"
      },
      "outputs": [],
      "source": [
        "def is_int_in_range(raw, lo: int, hi: int):\n",
        "    \"\"\"\n",
        "    Validate if input can be cast to int and falls in [lo, hi].\n",
        "    Returns (is_valid, value_or_None, error_message).\n",
        "    \"\"\"\n",
        "    s = str(raw).strip()\n",
        "    if not s:\n",
        "        return False, None, \"Input cannot be empty.\"\n",
        "    try:\n",
        "        v = int(s)\n",
        "        if lo <= v <= hi:\n",
        "            return True, v, None\n",
        "        return False, None, f\"Value must be between {lo} and {hi}.\"\n",
        "    except ValueError:\n",
        "        return False, None, \"Please enter a valid integer.\"\n",
        "\n",
        "\n",
        "\n",
        "def is_float_in_range(raw, lo: float, hi: float):\n",
        "    \"\"\"\n",
        "    Validate if input can be cast to float and falls in [lo, hi].\n",
        "    Returns (is_valid, value_or_None, error_message).\n",
        "    \"\"\"\n",
        "    s = str(raw).strip()\n",
        "    if not s:\n",
        "        return False, None, \"Input cannot be empty.\"\n",
        "    try:\n",
        "        v = float(s)\n",
        "        if lo <= v <= hi:\n",
        "            return True, v, None\n",
        "        return False, None, f\"Value must be between {lo} and {hi}.\"\n",
        "    except ValueError:\n",
        "        return False, None, \"Please enter a valid number.\"\n",
        "    except Exception:\n",
        "        # A broader exception catch for any unexpected issues\n",
        "        return False, None, \"An unexpected error occurred.\"\n",
        "\n",
        "\n",
        "def is_positive_float(raw):\n",
        "    \"\"\"\n",
        "    Validate if input can be cast to float and is strictly > 0.\n",
        "    Returns (is_valid, value_or_None, error_message).\n",
        "    \"\"\"\n",
        "    s = str(raw).strip()\n",
        "    if not s:\n",
        "        return False, None, \"Input cannot be empty.\"\n",
        "    try:\n",
        "        v = float(s)\n",
        "        if v > 0:\n",
        "            return True, v, None\n",
        "        return False, None, \"Value must be a positive number.\"\n",
        "    except ValueError:\n",
        "        return False, None, \"Please enter a valid number.\"\n",
        "\n",
        "\n",
        "def one_of(raw, options):\n",
        "    \"\"\"\n",
        "    Validate if input (case-insensitive) matches one of given options.\n",
        "    Returns (is_valid, canonical_value_or_None, error_message).\n",
        "    \"\"\"\n",
        "    s = str(raw).strip().lower()\n",
        "    mapping = {opt.lower(): opt for opt in options}\n",
        "    if s in mapping:\n",
        "        return True, mapping[s], None\n",
        "    return False, None, f\"Please enter one of: {', '.join(options)}.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rG3SrCTKqkxz"
      },
      "outputs": [],
      "source": [
        "def recommend_strategy(persona: str, risk: float, missed: int):\n",
        "    if risk >= 0.7:\n",
        "        if persona == \"cooperative\":\n",
        "            return \"offer_plan_high\"\n",
        "        if persona == \"aggressive\":\n",
        "            return \"senior_agent\"\n",
        "        if persona == \"confused\":\n",
        "            return \"educational_call\"\n",
        "        return \"escalate_call\"\n",
        "    elif 0.5 <= risk < 0.7:\n",
        "        if persona == \"cooperative\":\n",
        "            return \"reminder_payment\"\n",
        "        if persona == \"aggressive\":\n",
        "            return \"structured_negotiation\"\n",
        "        if persona == \"confused\":\n",
        "            return \"clarification_message\"\n",
        "        return \"follow_up_calls\"\n",
        "    else:\n",
        "        if missed > 0:\n",
        "            return \"soft_reminder\"\n",
        "        return \"no_contact\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YiaqubJqmP3"
      },
      "outputs": [],
      "source": [
        "def setup_page():\n",
        "    \"\"\"Display CLI banner for Loan Recovery Chatbot.\"\"\"\n",
        "    banner = \"\"\"\n",
        "=========================================\n",
        "        üí¨ Loan Recovery Chatbot\n",
        "=========================================\n",
        "    \"\"\"\n",
        "    print(banner)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDSNOtv5qy7Z"
      },
      "outputs": [],
      "source": [
        "_lgb_model = None\n",
        "_emotion_model = None\n",
        "\n",
        "def load_models():\n",
        "    \"\"\"Load LightGBM predictor and emotion classification pipeline (cached).\"\"\"\n",
        "    global _lgb_model, _emotion_model\n",
        "\n",
        "    # Load LGB model (only once)\n",
        "    if _lgb_model is None:\n",
        "        try:\n",
        "            _lgb_model = load_lgb_model()\n",
        "            print(\"‚úÖ LightGBM model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not load LightGBM model at '{model_path}': {e}\")\n",
        "            raise SystemExit(1)\n",
        "\n",
        "    # Load HuggingFace pipeline (only once)\n",
        "    if _emotion_model is None:\n",
        "        try:\n",
        "            _emotion_model = load_emotion_model()\n",
        "            print(\"‚úÖ Emotion model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Could not load emotion model: {e}\")\n",
        "            raise SystemExit(1)\n",
        "\n",
        "    return _lgb_model, _emotion_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fyeqPNOt1Hc"
      },
      "outputs": [],
      "source": [
        "def init_session():\n",
        "    \"\"\"\n",
        "    Initialize chatbot session state (CLI version).\n",
        "    Replaces Streamlit's session_state with a global Python dict.\n",
        "    \"\"\"\n",
        "    global session_state\n",
        "\n",
        "    if \"chat\" not in session_state:   # don‚Äôt overwrite if already exists\n",
        "        session_state = {\n",
        "            \"chat\": [],       # conversation history\n",
        "            \"answers\": {},    # collected answers\n",
        "            \"step\": 0,        # current question step\n",
        "            \"persona\": \"friendly\"  # default persona\n",
        "        }\n",
        "        print(\"‚úÖ [DEBUG] Chatbot session initialized.\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è [DEBUG] Session already initialized ‚Äî skipping reset.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "uTU_W4NAt3Bf"
      },
      "outputs": [],
      "source": [
        "def get_schema():\n",
        "    \"\"\"\n",
        "    Returns a list of dictionaries, where each dictionary defines a field\n",
        "    for data collection, including its name, prompt, and validation rule.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        {\n",
        "            \"name\": \"CustomerID\",\n",
        "            \"prompt\": \"Please share your Customer ID (format like CUST0001).\",\n",
        "            \"validation\": lambda raw: (\n",
        "                # Example of a custom validation for Customer ID using a simple regex check\n",
        "                True,\n",
        "                raw,\n",
        "                None\n",
        "            ) if str(raw).strip().startswith(\"CUST\") and len(str(raw).strip()) == 8 else (\n",
        "                False,\n",
        "                None,\n",
        "                \"Customer ID must start with 'CUST' and be 8 characters long.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Age\",\n",
        "            \"prompt\": \"What is your age? (18‚Äì75)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 18, 75)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"EmploymentStatus\",\n",
        "            \"prompt\": \"What is your employment status? (Self-Employed / Salaried / Student / Unemployed)\",\n",
        "            \"validation\": lambda raw: one_of(raw, [\"Self-Employed\", \"Salaried\", \"Student\", \"Unemployed\"])\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Income\",\n",
        "            \"prompt\": \"Your annual income in INR? (positive number)\",\n",
        "            \"validation\": lambda raw: is_positive_float(raw)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Location\",\n",
        "            \"prompt\": \"Your location? (Urban / Suburban / Rural)\",\n",
        "            \"validation\": lambda raw: one_of(raw, [\"Urban\", \"Suburban\", \"Rural\"])\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"LoanType\",\n",
        "            \"prompt\": \"Loan type? (Personal / Auto / Home / Education / Business)\",\n",
        "            \"validation\": lambda raw: one_of(raw, [\"Personal\", \"Auto\", \"Home\", \"Education\", \"Business\"])\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"LoanAmount\",\n",
        "            \"prompt\": \"Loan amount in INR? (positive number)\",\n",
        "            \"validation\": lambda raw: is_positive_float(raw)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"TenureMonths\",\n",
        "            \"prompt\": \"Loan tenure in months? (6‚Äì360)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 6, 360)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"InterestRate\",\n",
        "            \"prompt\": \"Interest rate (%)? (1‚Äì30)\",\n",
        "            \"validation\": lambda raw: is_float_in_range(raw, 1.0, 30.0)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"MissedPayments\",\n",
        "            \"prompt\": \"Number of missed payments? (0‚Äì24)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 24)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"DelaysDays\",\n",
        "            \"prompt\": \"Total delay in days? (0‚Äì365)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 365)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"InteractionAttempts\",\n",
        "            \"prompt\": \"How many contact attempts so far? (0‚Äì50)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 50)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ResponseTimeHours\",\n",
        "            \"prompt\": \"Average response time in hours? (0‚Äì240)\",\n",
        "            \"validation\": lambda raw: is_float_in_range(raw, 0.0, 240.0)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"AppUsageFrequency\",\n",
        "            \"prompt\": \"App usage frequency score (0‚Äì100)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 100)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"WebsiteVisits\",\n",
        "            \"prompt\": \"Website visits (0‚Äì500)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 500)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"Complaints\",\n",
        "            \"prompt\": \"Number of complaints raised? (0‚Äì50)\",\n",
        "            \"validation\": lambda raw: is_int_in_range(raw, 0, 50)\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"UserMessage\",\n",
        "            \"prompt\": \"Lastly, how do you feel about repayment? (free text)\",\n",
        "            \"validation\": lambda raw: (True, raw, None)  # Free text, no specific validation\n",
        "        }\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "827XA8-ct4Zt"
      },
      "outputs": [],
      "source": [
        "def display_chat():\n",
        "    \"\"\"Print chat history in CLI-friendly format.\"\"\"\n",
        "    if \"chat\" not in session_state:\n",
        "        session_state[\"chat\"] = []  # safeguard\n",
        "\n",
        "    for speaker, msg in session_state[\"chat\"]:\n",
        "        if speaker == \"bot\":\n",
        "            print(f\"\\nü§ñ Bot: {msg}\")\n",
        "        else:\n",
        "            print(f\"üë§ You: {msg}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wWlJ8-lt7f3"
      },
      "outputs": [],
      "source": [
        "def get_next_question(schema):\n",
        "    # Add PartialPayments if MissedPayments > 0\n",
        "    dynamic_schema = schema.copy()\n",
        "    if \"MissedPayments\" in session_state[\"answers\"]:\n",
        "        try:\n",
        "            mp = int(session_state[\"answers\"][\"MissedPayments\"])\n",
        "        except:\n",
        "            mp = 0\n",
        "        if mp > 0 and not any(k == \"PartialPayments\" for k, _ in dynamic_schema):\n",
        "            idx = next((i for i, (k, _) in enumerate(dynamic_schema) if k == \"DelaysDays\"), len(dynamic_schema))\n",
        "            dynamic_schema.insert(idx, (\"PartialPayments\", \"Partial payments made so far? (0‚Äì24)\"))\n",
        "\n",
        "    # Return next unanswered question\n",
        "    for k, q in dynamic_schema:\n",
        "        if k not in session_state[\"answers\"]:\n",
        "            return k, q\n",
        "    return None, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5JaiDpSt91z"
      },
      "outputs": [],
      "source": [
        "def process_answer(key, raw, emotion_pipe):\n",
        "    \"\"\"\n",
        "    Validate and process user answers according to schema.\n",
        "    Returns (valid: bool, parsed_value, error_message: str|None).\n",
        "    \"\"\"\n",
        "\n",
        "    # --- Numeric fields ---\n",
        "    if key == \"Age\":\n",
        "        return (*is_int_in_range(raw, 18, 75), \"Age must be between 18 and 75.\")\n",
        "    if key == \"Income\":\n",
        "        return (*is_positive_float(raw), \"Income must be a positive number.\")\n",
        "    if key == \"LoanAmount\":\n",
        "        return (*is_positive_float(raw), \"Loan amount must be positive.\")\n",
        "    if key == \"TenureMonths\":\n",
        "        return (*is_int_in_range(raw, 6, 360), \"Tenure must be 6‚Äì360 months.\")\n",
        "    if key == \"InterestRate\":\n",
        "        return (*is_float_in_range(raw, 1, 30), \"Interest rate must be 1‚Äì30%.\")\n",
        "    if key == \"MissedPayments\":\n",
        "        return (*is_int_in_range(raw, 0, 24), \"Missed payments must be 0‚Äì24.\")\n",
        "    if key == \"PartialPayments\":\n",
        "        return (*is_int_in_range(raw, 0, 24), \"Partial payments must be 0‚Äì24.\")\n",
        "    if key == \"DelaysDays\":\n",
        "        return (*is_int_in_range(raw, 0, 365), \"Delays must be 0‚Äì365 days.\")\n",
        "    if key == \"InteractionAttempts\":\n",
        "        return (*is_int_in_range(raw, 0, 50), \"Interaction attempts must be 0‚Äì50.\")\n",
        "    if key == \"ResponseTimeHours\":\n",
        "        return (*is_float_in_range(raw, 0, 240), \"Response time must be 0‚Äì240 hours.\")\n",
        "    if key == \"AppUsageFrequency\":\n",
        "        return (*is_float_in_range(raw, 0, 100), \"App usage frequency must be 0‚Äì100.\")\n",
        "    if key == \"WebsiteVisits\":\n",
        "        return (*is_int_in_range(raw, 0, 500), \"Website visits must be 0‚Äì500.\")\n",
        "    if key == \"Complaints\":\n",
        "        return (*is_int_in_range(raw, 0, 50), \"Complaints must be 0‚Äì50.\")\n",
        "\n",
        "    # --- Categorical fields ---\n",
        "    if key == \"EmploymentStatus\":\n",
        "        valid, val = one_of(raw, [\"Self-Employed\", \"Salaried\", \"Student\", \"Unemployed\"])\n",
        "        return valid, val, None if valid else f\"Invalid input '{raw}'. Must be one of: Self-Employed / Salaried / Student / Unemployed.\"\n",
        "    if key == \"Location\":\n",
        "        valid, val = one_of(raw, [\"Urban\", \"Suburban\", \"Rural\"])\n",
        "        return valid, val, None if valid else f\"Invalid input '{raw}'. Must be one of: Urban / Suburban / Rural.\"\n",
        "    if key == \"LoanType\":\n",
        "        valid, val = one_of(raw, [\"Personal\", \"Auto\", \"Home\", \"Education\", \"Business\"])\n",
        "        return valid, val, None if valid else f\"Invalid input '{raw}'. Must be one of: Personal / Auto / Home / Education / Business.\"\n",
        "\n",
        "    # --- Free text fields ---\n",
        "    if key == \"CustomerID\":\n",
        "        s = str(raw).strip()\n",
        "        if s:\n",
        "            return True, s, None\n",
        "        return False, None, \"Customer ID cannot be empty.\"\n",
        "\n",
        "    if key == \"UserMessage\":\n",
        "        s = str(raw).strip()\n",
        "        if not s:\n",
        "            return False, None, \"Message cannot be empty.\"\n",
        "        # Run emotion classification\n",
        "        emo_result = emotion_pipe(s)[0][0]  # extract first prediction\n",
        "        return True, {\"text\": s, \"emotion\": emo_result[\"label\"], \"score\": emo_result[\"score\"]}, None\n",
        "\n",
        "    # --- Unknown field ---\n",
        "    return False, None, f\"Unknown field '{key}'.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPtfjBxJt_pj"
      },
      "outputs": [],
      "source": [
        "def analyze_and_recommend(lgb):\n",
        "    print(\"‚úÖ Thanks! Analyzing your responses‚Ä¶\")\n",
        "    A = session_state[\"answers\"]\n",
        "\n",
        "    # Ensure PartialPayments is set\n",
        "    if \"PartialPayments\" not in A:\n",
        "        A[\"PartialPayments\"] = 0\n",
        "\n",
        "    # Extract sentiment from UserMessage if present\n",
        "    if \"UserMessage\" in A and isinstance(A[\"UserMessage\"], dict):\n",
        "        A[\"SentimentLabel\"] = A[\"UserMessage\"][\"emotion\"]\n",
        "        A[\"SentimentScore\"] = normalize_sentiment_score(\n",
        "            A[\"UserMessage\"][\"emotion\"], A[\"UserMessage\"][\"score\"]\n",
        "        )\n",
        "    else:\n",
        "        A[\"SentimentLabel\"] = \"neutral\"\n",
        "        A[\"SentimentScore\"] = 0.0\n",
        "\n",
        "    # Features used by LightGBM\n",
        "    feature_cols = [\n",
        "        \"Age\",\"Income\",\"LoanAmount\",\"TenureMonths\",\"InterestRate\",\n",
        "        \"MissedPayments\",\"DelaysDays\",\"PartialPayments\",\"InteractionAttempts\",\n",
        "        \"ResponseTimeHours\",\"AppUsageFrequency\",\"WebsiteVisits\",\"Complaints\",\n",
        "        \"SentimentScore\"\n",
        "    ]\n",
        "\n",
        "    def num(x, default=0.0):\n",
        "        try:\n",
        "            return float(x)\n",
        "        except Exception:\n",
        "            print(f\"‚ö†Ô∏è Missing/invalid feature -> using default {default}\")\n",
        "            return float(default)\n",
        "\n",
        "    X = [[num(A.get(col, 0)) for col in feature_cols]]\n",
        "\n",
        "    # --- Predict risk ---\n",
        "    try:\n",
        "        if hasattr(lgb, \"predict_proba\"):\n",
        "            risk = float(lgb.predict_proba(X)[0][1])\n",
        "        else:\n",
        "            risk = float(lgb.predict(X)[0])\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Prediction error: {e}\")\n",
        "        return {\"error\": f\"Prediction failed: {e}\"}\n",
        "\n",
        "    target = \"Yes\" if risk >= 0.5 else \"No\"\n",
        "\n",
        "    # Persona detection\n",
        "    persona = A.get(\"Persona\") or EMO_TO_PERSONA.get(\n",
        "        A.get(\"SentimentLabel\", \"neutral\"), \"evasive\"\n",
        "    )\n",
        "\n",
        "    strategy = recommend_strategy(\n",
        "        persona, risk, int(A.get(\"MissedPayments\", 0))\n",
        "    )\n",
        "\n",
        "    # Update answers\n",
        "    A.update({\n",
        "        \"RiskScore\": risk,\n",
        "        \"Target\": target,\n",
        "        \"Persona\": persona,\n",
        "        \"RecommendedStrategy\": strategy\n",
        "    })\n",
        "\n",
        "    # --- CLI Results ---\n",
        "    print(\"\\n--- Analysis Results ---\")\n",
        "    print(f\"üìä Will Miss Next Payment (Target): {target}\")\n",
        "    print(f\"üî¢ Risk Score: {risk:.3f}\")\n",
        "    print(f\"üß© Persona Detected: {persona}\")\n",
        "    print(f\"üéØ Recommended Strategy: {strategy}\")\n",
        "    print(\"-------------------------\\n\")\n",
        "\n",
        "    # --- Save to DB ---\n",
        "    save_session_to_db(A)\n",
        "\n",
        "    return A\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global session_state replacement for CLI mode\n",
        "session_state = {\n",
        "    \"chat\": [],\n",
        "    \"answers\": {},\n",
        "    \"step\": 0,\n",
        "    \"persona\": \"default\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "R6W36R2ByuAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "IJ6P3R9XuDkl",
        "outputId": "38fcdc29-09be-4b2d-a280-f569fc84d18f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "üí¨ Loan Assistant Chatbot (CLI)\n",
            "==============================\n",
            "\n",
            "‚ùå Database connection failed: connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n",
            "\tIs the server running on that host and accepting TCP/IP connections?\n",
            "connection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n",
            "\tIs the server running on that host and accepting TCP/IP connections?\n",
            "\n",
            "‚ö†Ô∏è Skipping DB init ‚Äî connection unavailable.\n",
            "‚ÑπÔ∏è [DEBUG] Session already initialized ‚Äî skipping reset.\n",
            "\n",
            "ü§ñ Bot: üôÇ What is your age? (18‚Äì75)\n",
            "üë§ You: 10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 3)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-132447811.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mcli_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-132447811.py\u001b[0m in \u001b[0;36mcli_chatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# process answer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_answer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_ans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"‚ö†Ô∏è {err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "def cli_chatbot():\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"üí¨ Loan Assistant Chatbot (CLI)\")\n",
        "    print(\"==============================\\n\")\n",
        "\n",
        "    # --- Setup ---\n",
        "    init_db()\n",
        "    lgb, emotion_pipe = load_models()\n",
        "    init_session()\n",
        "    schema = get_schema()\n",
        "\n",
        "    while True:\n",
        "        # check next question\n",
        "        key, question = get_next_question(schema)\n",
        "\n",
        "        if key:\n",
        "            bot_q = tone_question(session_state[\"persona\"], question)\n",
        "\n",
        "            # print bot question\n",
        "            print(f\"\\nü§ñ Bot: {bot_q}\")\n",
        "\n",
        "            # get user input\n",
        "            user_ans = input(\"üë§ You: \").strip()\n",
        "\n",
        "            if not user_ans:\n",
        "                print(\"‚ö†Ô∏è Please provide a valid response.\")\n",
        "                continue\n",
        "\n",
        "            # process answer\n",
        "            valid, parsed, err = process_answer(key, user_ans, emotion_pipe)\n",
        "            if not valid:\n",
        "                print(f\"‚ö†Ô∏è {err}\")\n",
        "                continue\n",
        "\n",
        "            # save session state\n",
        "            session_state[\"answers\"][key] = parsed\n",
        "            session_state[\"chat\"].append((\"bot\", bot_q))\n",
        "            session_state[\"chat\"].append((\"user\", user_ans))\n",
        "            session_state[\"step\"] += 1\n",
        "\n",
        "        else:\n",
        "            # all questions answered ‚Üí analyze\n",
        "            print(\"\\nüìä Analyzing your profile and generating recommendation...\\n\")\n",
        "            analyze_and_recommend(lgb)\n",
        "\n",
        "        if user_ans.lower() in [\"quit\", \"exit\", \"q\"]:\n",
        "            print(\"üëã Exiting chatbot. Bye!\")\n",
        "            break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    cli_chatbot()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}