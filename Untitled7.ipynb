{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V5xV6-X_dCEr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib,os\n",
        "\n",
        "import re, joblib, matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from dataclasses import dataclass\n",
        "from typing import Callable, Optional, Any, Tuple, List, Dict\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "try:\n",
        "    import lightgbm as lgb\n",
        "except ImportError:\n",
        "    lgb = None\n",
        "    from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "_SENTIMENT_PIPE=None\n",
        "def get_sentiment_pipe():\n",
        "    global _SENTIMENT_PIPE\n",
        "    if _SENTIMENT_PIPE is None:\n",
        "        _SENTIMENT_PIPE = pipeline(\"sentiment-analysis\")\n",
        "    return _SENTIMENT_PIPE\n",
        "\n",
        "def analyze_sentiment(text:str):\n",
        "    if not text.strip():\n",
        "        return \"neutral\", 0.0\n",
        "    res = get_sentiment_pipe()(text[:512])[0]\n",
        "    label = res['label'].lower()\n",
        "    score = res['score'] if label in [\"positive\",\"negative\"] else 0.0\n",
        "    return label, score if label==\"positive\" else -score if label==\"negative\" else 0.0"
      ],
      "metadata": {
        "id": "_8l5XmmvgyTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Analytics_loan_collection_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "MODEL_PATH = os.environ.get(\"MODEL_PATH\", \"/content/drive/MyDrive/Colab Notebooks/loan_default_predictor.pkl\")\n",
        "DB_URL = os.environ.get(\"DB_URL\", \"postgresql://username:password@localhost:5432/chatbot_db\")\n",
        "RETRAIN_THRESHOLD = int(os.environ.get(\"RETRAIN_THRESHOLD\", \"1000\"))\n",
        "DEFAULT_SENTIMENT_MODEL = os.environ.get(\"DEFAULT_SENTIMENT_MODEL\", \"j-hartmann/emotion-english-distilroberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNjB7GNjeG0Y",
        "outputId": "d6264bbc-abd1-4d7c-892c-be712691daf6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ACTIONS = [\n",
        "    \"no_contact\",\n",
        "    \"soft_reminder\",\n",
        "    \"reminder_payment\",\n",
        "    \"offer_plan_low\",\n",
        "    \"offer_plan_high\",\n",
        "    \"escalate_call\",\n",
        "    \"senior_agent\",\n",
        "    \"legal_notice\"\n",
        "]\n",
        "EPSILON = float(os.environ.get(\"POLICY_EPSILON\", \"0.05\"))\n",
        "POLICY_REFERENCE = os.environ.get(\"POLICY_REFERENCE\", \"heuristic_v1\")\n",
        "\n",
        "_model = None\n",
        "MODEL_FEATURES: List[str] = []\n",
        "CATEGORICAL_FEATURES: List[str] = []\n",
        "\n",
        "# Lazy HF pipelines\n",
        "_HF_PIPELINES = {\"sentiment\": None, \"zero_shot\": None, \"llm\": None}\n",
        "\n",
        "# Intent classifier objects\n",
        "INTENT_VECT = None\n",
        "INTENT_CLF = None\n",
        "INTENT_LABELS = None\n",
        "\n",
        "LLM_MODEL_NAME = None  # set to a model id to enable LLM templating\n",
        "\n",
        "def load_model(path: str = MODEL_PATH) -> Tuple[Any, list, list]:\n",
        "    global _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"Model file not found at {path}\")\n",
        "    data = joblib.load(path)\n",
        "    _model = data.get(\"model\")\n",
        "    MODEL_FEATURES = data.get(\"features\", [])\n",
        "    CATEGORICAL_FEATURES = data.get(\"categorical\", []) or []\n",
        "    logger.info(f\"Loaded model from {path}. Feature count: {len(MODEL_FEATURES)}\")\n",
        "    return _model, MODEL_FEATURES, CATEGORICAL_FEATURES\n",
        "\n",
        "def get_engine(db_url: str = DB_URL):\n",
        "    return create_engine(db_url, future=True)"
      ],
      "metadata": {
        "id": "Xj4fEEHge2BL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- HF PIPELINE HELPERS (lazy) ----------\n",
        "def get_sentiment_pipeline(model_name: str = DEFAULT_SENTIMENT_MODEL):\n",
        "    if _HF_PIPELINES[\"sentiment\"] is None:\n",
        "        logger.info(f\"Loading emotion pipeline ({model_name})\")\n",
        "        # For emotion model, return all scores for each emotion class\n",
        "        _HF_PIPELINES[\"sentiment\"] = hf_pipeline(\n",
        "            \"text-classification\",\n",
        "            model=model_name,\n",
        "            return_all_scores=True\n",
        "        )\n",
        "    return _HF_PIPELINES[\"sentiment\"]\n",
        "\n",
        "def get_zero_shot_pipeline():\n",
        "    if _HF_PIPELINES[\"zero_shot\"] is None:\n",
        "        logger.info(\"Loading zero-shot classification pipeline (facebook/bart-large-mnli)\")\n",
        "        _HF_PIPELINES[\"zero_shot\"] = hf_pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "    return _HF_PIPELINES[\"zero_shot\"]\n",
        "\n",
        "def get_llm_pipeline(model_name: str):\n",
        "    if model_name is None:\n",
        "        return None\n",
        "    if _HF_PIPELINES[\"llm\"] is None or LLM_MODEL_NAME != model_name:\n",
        "        logger.info(f\"Loading LLM pipeline: {model_name}\")\n",
        "        _HF_PIPELINES[\"llm\"] = hf_pipeline(\"text-generation\", model=model_name)\n",
        "    return _HF_PIPELINES[\"llm\"]"
      ],
      "metadata": {
        "id": "RDoC2xwr9EA1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- SENTIMENT (EMOTION) ANALYZER ----------\n",
        "def analyze_sentiment(text: str) -> Tuple[str, float]:\n",
        "    \"\"\"Return top emotion label and its confidence score (0..1).\"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return \"neutral\", 0.0\n",
        "    try:\n",
        "        sentiment = get_sentiment_pipeline()\n",
        "        results = sentiment(text[:512])[0]  # List of dicts: [{'label':..., 'score':...}, ...]\n",
        "        top_emotion = max(results, key=lambda x: x['score'])\n",
        "        label = top_emotion['label'].lower()  # e.g. \"joy\", \"anger\", \"sadness\"\n",
        "        score = float(top_emotion['score'])\n",
        "        return label, score\n",
        "    except Exception:\n",
        "        logger.exception(\"Emotion analysis failed; returning neutral\")\n",
        "        return \"neutral\", 0.0\n",
        "\n",
        "def detect_persona(sentiment_label: str, message: str, user_features: Optional[dict] = None) -> str:\n",
        "    \"\"\"\n",
        "    Heuristic-based persona detection.\n",
        "    \"\"\"\n",
        "    msg = (message or \"\").strip()\n",
        "    user_features = user_features or {}\n",
        "    missed = int(user_features.get(\"MissedPayments\", 0) or 0)\n",
        "    response_time = user_features.get(\"ResponseTimeHours\", None)\n",
        "\n",
        "    # Adapted heuristics using emotion labels instead of simple POSITIVE/NEGATIVE\n",
        "    if sentiment_label in (\"joy\", \"love\", \"surprise\") and missed <= 1:\n",
        "        return \"cooperative\"\n",
        "    if sentiment_label in (\"anger\", \"fear\", \"sadness\") and (\"!\" in msg or len(msg) < 40):\n",
        "        return \"aggressive\"\n",
        "    if \"?\" in msg or \"don't understand\" in msg.lower() or \"how\" in msg.lower():\n",
        "        return \"confused\"\n",
        "    if missed >= 2 or (response_time is not None and response_time > 48):\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n"
      ],
      "metadata": {
        "id": "SGFoFdJO9Iq8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#---------- STRATEGY RECOMMENDATION (legacy/helper mapping) ----------\n",
        "ACTION_TO_STRATEGY = {\n",
        "    \"no_contact\": {\"code\": \"monitor\", \"description\": \"Continue monitoring.\"},\n",
        "    \"soft_reminder\": {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app/email.\"},\n",
        "    \"reminder_payment\": {\"code\": \"reminder\", \"description\": \"SMS + payment link.\"},\n",
        "    \"offer_plan_low\": {\"code\": \"offer_plan_low\", \"description\": \"Offer low-leniency repayment plan.\"},\n",
        "    \"offer_plan_high\": {\"code\": \"offer_plan_high\", \"description\": \"Offer high-leniency plan with discount.\"},\n",
        "    \"escalate_call\": {\"code\": \"escalate_call\", \"description\": \"Schedule agent call.\"},\n",
        "    \"senior_agent\": {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent.\"},\n",
        "    \"legal_notice\": {\"code\": \"legal_notice\", \"description\": \"Initiate legal review / notice (guarded).\"}\n",
        "}\n",
        "\n",
        "def recommend_strategy(risk_score: float, persona: str, sentiment_label: str) -> Dict[str, str]:\n",
        "    \"\"\"Legacy function retained for backwards compatibility but not used for policy sampling.\"\"\"\n",
        "    if risk_score >= 0.8:\n",
        "        if persona == \"cooperative\":\n",
        "            return {\"code\": \"offer_plan_high\", \"description\": \"Offer structured repayment plan with possible small discount.\"}\n",
        "        elif persona == \"evasive\":\n",
        "            return {\"code\": \"escalate_call\", \"description\": \"Schedule personalized call and frequent reminders.\"}\n",
        "        elif persona == \"aggressive\":\n",
        "            return {\"code\": \"senior_agent\", \"description\": \"Escalate to senior agent for sensitive handling.\"}\n",
        "        else:\n",
        "            return {\"code\": \"contact_high\", \"description\": \"Immediate outreach via call and SMS.\"}\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        if sentiment_label in (\"anger\", \"fear\", \"sadness\"):\n",
        "            return {\"code\": \"empathetic_reminder\", \"description\": \"Send empathetic SMS + email with options.\"}\n",
        "        else:\n",
        "            return {\"code\": \"reminder\", \"description\": \"Send reminder SMS + email with payment link.\"}\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        return {\"code\": \"soft_reminder\", \"description\": \"Soft reminder via app notification and email.\"}\n",
        "    else:\n",
        "        return {\"code\": \"monitor\", \"description\": \"No immediate action — continue monitoring.\"}\n",
        "\n",
        "# ---------- PHASE-2: Policy / Action Probabilities & Sampling ----------\n",
        "from math import exp\n",
        "\n",
        "def score_to_action_probs(risk_score: float, persona: str, profile: dict) -> Dict[str, Any]:\n",
        "    logits = {a: 0.0 for a in ACTIONS}\n",
        "\n",
        "    if risk_score >= 0.8:\n",
        "        logits.update({\n",
        "            \"offer_plan_high\": 3.0 if persona == \"cooperative\" else 1.0,\n",
        "            \"escalate_call\": 2.0 if persona in (\"evasive\", \"neutral\") else 0.5,\n",
        "            \"senior_agent\": 2.5 if persona == \"aggressive\" else 0.1,\n",
        "            \"legal_notice\": 0.5\n",
        "        })\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        logits.update({\n",
        "            \"reminder_payment\": 2.5,\n",
        "            \"offer_plan_low\": 1.8 if persona == \"cooperative\" else 0.6,\n",
        "            \"escalate_call\": 0.8 if persona == \"evasive\" else 0.2\n",
        "        })\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        logits.update({\"soft_reminder\": 2.0, \"reminder_payment\": 0.5})\n",
        "    else:\n",
        "        logits.update({\"no_contact\": 2.0, \"soft_reminder\": 0.5})\n",
        "\n",
        "    if persona == \"confused\":\n",
        "        logits[\"offer_plan_low\"] += 0.5\n",
        "        logits[\"reminder_payment\"] += 0.5\n",
        "    if persona == \"aggressive\":\n",
        "        logits[\"senior_agent\"] += 1.0\n",
        "        logits[\"offer_plan_high\"] -= 0.5\n",
        "    if persona == \"evasive\":\n",
        "        logits[\"escalate_call\"] += 1.0\n",
        "\n",
        "    missed = int(profile.get(\"MissedPayments\", 0) or 0)\n",
        "    if missed < 3:\n",
        "        logits[\"legal_notice\"] = -999.0\n",
        "\n",
        "    vals = list(logits.values())\n",
        "    maxv = max(vals)\n",
        "    exp_vals = [exp(v - maxv) for v in vals]\n",
        "    s = sum(exp_vals)\n",
        "    probs = [v / s for v in exp_vals]\n",
        "    return {\"probs\": probs, \"policy_reason\": f\"heuristic_risk:{risk_score:.2f}_persona:{persona}\", \"base_scores\": logits}\n",
        "\n",
        "def sample_action(probs: List[float], epsilon: float = EPSILON) -> Tuple[str, float, List[float]]:\n",
        "    probs = np.array(probs, dtype=float)\n",
        "    probs = probs / probs.sum()\n",
        "\n",
        "    if np.random.rand() < epsilon:\n",
        "        final_probs = np.ones_like(probs) / len(probs)\n",
        "    else:\n",
        "        final_probs = probs\n",
        "\n",
        "    action_idx = int(np.random.choice(np.arange(len(final_probs)), p=final_probs))\n",
        "    action = ACTIONS[action_idx]\n",
        "    propensity = float(final_probs[action_idx])\n",
        "    return action, propensity, final_probs.tolist()"
      ],
      "metadata": {
        "id": "hH5Rt3_n9dPM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "@dataclass\n",
        "class FieldSpec:\n",
        "    name: str\n",
        "    prompt: str\n",
        "    validator: Callable[[str], Tuple[bool, Optional[Any], str]]\n",
        "    required: bool = True\n",
        "    depends_on: Optional[Callable[[Dict[str, Any]], bool]] = None\n",
        "\n",
        "def int_in_range(min_v: int, max_v: int):\n",
        "    def _v(x: str):\n",
        "        x = x.strip()\n",
        "        if not re.fullmatch(r\"-?\\d+\", x):\n",
        "            return False, None, f\"Please enter a whole number between {min_v} and {max_v}.\"\n",
        "        val = int(x)\n",
        "        if not (min_v <= val <= max_v):\n",
        "            return False, None, f\"Value must be between {min_v} and {max_v}.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def float_in_range(min_v: float, max_v: float):\n",
        "    def _v(x: str):\n",
        "        x = x.strip().replace(\",\", \"\")\n",
        "        try:\n",
        "            val = float(x)\n",
        "        except ValueError:\n",
        "            return False, None, f\"Please enter a number between {min_v} and {max_v}.\"\n",
        "        if not (min_v <= val <= max_v):\n",
        "            return False, None, f\"Value must be between {min_v} and {max_v}.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def positive_float():\n",
        "    def _v(x: str):\n",
        "        x = x.strip().replace(\",\", \"\")\n",
        "        try:\n",
        "            val = float(x)\n",
        "        except ValueError:\n",
        "            return False, None, \"Please enter a positive number.\"\n",
        "        if val <= 0:\n",
        "            return False, None, \"Value must be > 0.\"\n",
        "        return True, val, \"\"\n",
        "    return _v\n",
        "\n",
        "def one_of(options: List[str]):\n",
        "    lower_opts = [o.lower() for o in options]\n",
        "    def _v(x: str):\n",
        "        s = x.strip()\n",
        "        if s.lower() not in lower_opts:\n",
        "            return False, None, f\"Please choose one of: {', '.join(options)}.\"\n",
        "        return True, options[lower_opts.index(s.lower())], \"\"\n",
        "    return _v\n",
        "\n",
        "def income_optional_if_unemployed_or_student(state: Dict[str, Any]) -> bool:\n",
        "    status = state.get(\"EmploymentStatus\", \"\").lower()\n",
        "    return status not in {\"unemployed\", \"student\"}\n",
        "\n",
        "def partial_payments_if_missed(state: Dict[str, Any]) -> bool:\n",
        "    return state.get(\"MissedPayments\", 0) > 0\n",
        "\n",
        "# %% [markdown\n",
        "# ## 4. Chatbot Schema\n",
        "\n",
        "# %%\n",
        "SCHEMA: List[FieldSpec] = [\n",
        "    FieldSpec(\n",
        "        \"CustomerID\",\n",
        "        \"Enter your Customer ID (format: CUST0001, CUST0002, etc.):\",\n",
        "        lambda s: (bool(re.fullmatch(r\"CUST\\d{4}\", s.strip())), s.strip(),\n",
        "                   \"Customer ID must be in format 'CUST' followed by 4 digits, e.g., CUST0001.\")\n",
        "    ),\n",
        "    FieldSpec(\"Age\", \"Please enter your age (18–75):\", int_in_range(18, 75)),\n",
        "    FieldSpec(\"Income\", \"Annual income in INR (e.g., 450000):\", positive_float(), depends_on=income_optional_if_unemployed_or_student),\n",
        "    FieldSpec(\"Location\", \"Your location (Urban/Suburban/Rural):\", one_of([\"Urban\", \"Suburban\", \"Rural\"])),\n",
        "    FieldSpec(\"EmploymentStatus\", \"Employment status (Self-Employed/Salaried/Student/Unemployed):\",\n",
        "              one_of([\"Self-Employed\", \"Salaried\", \"Student\", \"Unemployed\"])),\n",
        "    FieldSpec(\"LoanAmount\", \"Requested loan amount in INR (must be > 0):\", positive_float()),\n",
        "    FieldSpec(\"TenureMonths\", \"Loan tenure in months (6–360):\", int_in_range(6, 360)),\n",
        "    FieldSpec(\"InterestRate\", \"Annual interest rate in % (1–30):\", float_in_range(1.0, 30.0)),\n",
        "    FieldSpec(\"LoanType\", \"Type of loan (Personal/Auto/Home/Education/Business):\",\n",
        "              one_of([\"Personal\", \"Auto\", \"Home\", \"Education\", \"Business\"])),\n",
        "\n",
        "    FieldSpec(\"MissedPayments\", \"Number of missed payments (0–24):\", int_in_range(0, 24)),\n",
        "    FieldSpec(\"DelaysDays\", \"Total delay in days (0–365):\", int_in_range(0, 365)),\n",
        "    FieldSpec(\"PartialPayments\", \"Number of partial payments (0–24):\", int_in_range(0, 24), depends_on=partial_payments_if_missed),\n",
        "    FieldSpec(\"InteractionAttempts\", \"Number of contact attempts made (0–50):\", int_in_range(0, 50)),\n",
        "    FieldSpec(\"ResponseTimeHours\", \"Average response time in hours (0–240):\", float_in_range(0.0, 240.0)),\n",
        "    FieldSpec(\"AppUsageFrequency\", \"App usage frequency score (0–100):\", float_in_range(0.0, 100.0)),\n",
        "    FieldSpec(\"WebsiteVisits\", \"Number of visits to the loan portal (0–500):\", int_in_range(0, 500)),\n",
        "    FieldSpec(\"Complaints\", \"Number of complaints registered (0–50):\", int_in_range(0, 50)),\n",
        "    ]"
      ],
      "metadata": {
        "id": "NECXmmjj-DbN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% [markdown\n",
        "# ## 5️⃣ Chatbot Interactive Engine\n",
        "\n",
        "# %%\n",
        "def ask_field(field: FieldSpec, state: dict, transcript: list):\n",
        "    \"\"\"Ask one field from the user, validate, and return the value.\"\"\"\n",
        "    while True:\n",
        "        val = input(f\"{field.prompt}\\n> \").strip()\n",
        "\n",
        "        # If not required and left blank\n",
        "        if not val and not field.required:\n",
        "            transcript.append((field.prompt, None))\n",
        "            return None\n",
        "\n",
        "        ok, v, err = field.validator(val)\n",
        "        if ok:\n",
        "            transcript.append((field.prompt, val))\n",
        "            return v\n",
        "        else:\n",
        "            print(f\"❌ Invalid: {err}\")\n",
        "\n",
        "\n",
        "def collect_user_inputs():\n",
        "    \"\"\"Loop through schema, handle depends_on, build state + transcript.\"\"\"\n",
        "    state = {}\n",
        "    transcript = []\n",
        "\n",
        "    for f in SCHEMA:\n",
        "        # Skip conditional fields\n",
        "        if f.depends_on and not f.depends_on(state):\n",
        "            continue\n",
        "        state[f.name] = ask_field(f, state, transcript)\n",
        "\n",
        "    return state, transcript\n",
        "\n",
        "# %% [markdown\n",
        "# ## 6️⃣ Compute Sentiment, Predict Target, Persona & Strategy\n",
        "\n",
        "# %%\n",
        "def auto_sentiment_score(state: dict) -> float:\n",
        "    # Combine all text fields if any (for demo, just 0)\n",
        "    return 0.0\n",
        "\n",
        "def compute_risk_target_persona_strategy(user_state: dict):\n",
        "    # Sentiment\n",
        "    text_inputs = \" \".join(str(user_state.get(f,\"\")) for f in [\"CustomerID\",\"Location\",\"EmploymentStatus\",\"LoanType\"])\n",
        "    sentiment_label, sentiment_score = analyze_sentiment(text_inputs)\n",
        "    user_state[\"SentimentScore\"] = sentiment_score\n",
        "\n",
        "    # Predict risk\n",
        "    X_user = pd.DataFrame([user_state])[FEATURES]\n",
        "    risk_score = MODEL.predict_proba(X_user)[:,1][0]\n",
        "    user_state[\"Target\"] = \"Yes\" if risk_score>=0.5 else \"No\"\n",
        "\n",
        "    # Persona\n",
        "    user_state[\"Persona\"] = detect_persona(sentiment_label,\"\",user_state)\n",
        "\n",
        "    # Strategy\n",
        "    probs_data = score_to_action_probs(risk_score,user_state[\"Persona\"],user_state)\n",
        "    action,propensity,final_probs = sample_action(probs_data[\"probs\"])\n",
        "    user_state[\"RecommendedStrategy\"] = ACTION_TO_STRATEGY[action]\n",
        "    user_state[\"StrategyProbs\"] = final_probs\n",
        "    user_state[\"RiskScore\"] = risk_score\n",
        "    return user_state"
      ],
      "metadata": {
        "id": "UOZ3wjVg_Q03"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_field(field: FieldSpec, state: dict, transcript: list):\n",
        "    \"\"\"Ask one field from the user, validate, and return the value.\"\"\"\n",
        "    while True:\n",
        "        val = input(f\"{field.prompt}\\n> \").strip()\n",
        "\n",
        "        # If not required and left blank\n",
        "        if not val and not field.required:\n",
        "            transcript.append((field.prompt, None))\n",
        "            return None\n",
        "\n",
        "        ok, v, err = field.validator(val)\n",
        "        if ok:\n",
        "            transcript.append((field.prompt, val))\n",
        "            return v\n",
        "        else:\n",
        "            print(f\"❌ Invalid: {err}\")\n",
        "\n",
        "\n",
        "def collect_user_inputs():\n",
        "    \"\"\"Loop through schema, handle depends_on, build state + transcript.\"\"\"\n",
        "    state = {}\n",
        "    transcript = []\n",
        "\n",
        "    for f in SCHEMA:\n",
        "        # Skip conditional fields\n",
        "        if f.depends_on and not f.depends_on(state):\n",
        "            continue\n",
        "        state[f.name] = ask_field(f, state, transcript)\n",
        "\n",
        "    return state, transcript\n"
      ],
      "metadata": {
        "id": "ICEx6SKgGdLh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persona & tone\n",
        "TONE_MAP = {\n",
        "    \"cooperative\": \"friendly and informative\",\n",
        "    \"evasive\": \"polite but assertive\",\n",
        "    \"aggressive\": \"calm and empathetic\",\n",
        "    \"confused\": \"patient, clear, and supportive\",\n",
        "}\n",
        "\n",
        "def style_prompt(text: str, persona: str) -> str:\n",
        "    return f\"{TONE_MAP.get(persona, 'informative')}: {text}\"\n",
        "\n",
        "def style_error(msg: str, persona: str) -> str:\n",
        "    return f\"{TONE_MAP.get(persona, 'informative')}: {msg}\"\n",
        "\n",
        "def detect_persona(sentiment_label: str, message: str, user_features: Optional[dict] = None) -> str:\n",
        "    user_features = user_features or {}\n",
        "    missed = int(user_features.get(\"MissedPayments\", 0) or 0)\n",
        "    response_time = user_features.get(\"ResponseTimeHours\", None)\n",
        "    msg = (message or \"\").strip()\n",
        "    if sentiment_label in (\"joy\", \"love\", \"surprise\") and missed <= 1:\n",
        "        return \"cooperative\"\n",
        "    if sentiment_label in (\"anger\", \"fear\", \"sadness\") and (\"!\" in msg or len(msg) < 40):\n",
        "        return \"aggressive\"\n",
        "    if \"?\" in msg or \"don't understand\" in msg.lower():\n",
        "        return \"confused\"\n",
        "    if missed >= 2 or (response_time is not None and response_time > 48):\n",
        "        return \"evasive\"\n",
        "    return \"neutral\"\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 6. Predict Target\n",
        "\n",
        "# %%\n",
        "def predict_target(state: dict) -> float:\n",
        "    X_input = np.array([[state.get(f, 0) for f in MODEL_FEATURES]])\n",
        "    risk_score = _model.predict_proba(X_input)[0][1]\n",
        "    return risk_score\n",
        "\n",
        "# %% [markdown\n",
        "# ## 7. Strategy Recommendation\n",
        "\n",
        "# %%\n",
        "ACTIONS = [\"no_contact\",\"soft_reminder\",\"reminder_payment\",\"offer_plan_low\",\n",
        "           \"offer_plan_high\",\"escalate_call\",\"senior_agent\",\"legal_notice\"]\n",
        "\n",
        "EPSILON = 0.05  # for sampling randomness\n",
        "\n",
        "def score_to_action_probs(risk_score: float, persona: str, profile: dict) -> Dict[str, Any]:\n",
        "    logits = {a: 0.0 for a in ACTIONS}\n",
        "    if risk_score >= 0.8:\n",
        "        logits.update({\n",
        "            \"offer_plan_high\": 3.0 if persona == \"cooperative\" else 1.0,\n",
        "            \"escalate_call\": 2.0 if persona in (\"evasive\", \"neutral\") else 0.5,\n",
        "            \"senior_agent\": 2.5 if persona == \"aggressive\" else 0.1,\n",
        "            \"legal_notice\": 0.5\n",
        "        })\n",
        "    elif 0.5 <= risk_score < 0.8:\n",
        "        logits.update({\n",
        "            \"reminder_payment\": 2.5,\n",
        "            \"offer_plan_low\": 1.8 if persona == \"cooperative\" else 0.6,\n",
        "            \"escalate_call\": 0.8 if persona == \"evasive\" else 0.2\n",
        "        })\n",
        "    elif 0.3 <= risk_score < 0.5:\n",
        "        logits.update({\"soft_reminder\": 2.0, \"reminder_payment\": 0.5})\n",
        "    else:\n",
        "        logits.update({\"no_contact\": 2.0, \"soft_reminder\": 0.5})\n",
        "\n",
        "    if persona == \"confused\":\n",
        "        logits[\"offer_plan_low\"] += 0.5\n",
        "        logits[\"reminder_payment\"] += 0.5\n",
        "    if persona == \"aggressive\":\n",
        "        logits[\"senior_agent\"] += 1.0\n",
        "        logits[\"offer_plan_high\"] -= 0.5\n",
        "    if persona == \"evasive\":\n",
        "        logits[\"escalate_call\"] += 1.0\n",
        "\n",
        "    missed = int(profile.get(\"MissedPayments\", 0) or 0)\n",
        "    if missed < 3:\n",
        "        logits[\"legal_notice\"] = -999.0\n",
        "\n",
        "    vals = list(logits.values())\n",
        "    maxv = max(vals)\n",
        "    exp_vals = [exp(v - maxv) for v in vals]\n",
        "    s = sum(exp_vals)\n",
        "    probs = [v / s for v in exp_vals]\n",
        "    return {\"probs\": probs, \"policy_reason\": f\"heuristic_risk:{risk_score:.2f}_persona:{persona}\", \"base_scores\": logits}\n",
        "\n",
        "def sample_action(probs: List[float], epsilon: float = EPSILON) -> Tuple[str, float, List[float]]:\n",
        "    probs = np.array(probs, dtype=float)\n",
        "    probs = probs / probs.sum()\n",
        "    if np.random.rand() < epsilon:\n",
        "        final_probs = np.ones_like(probs) / len(probs)\n",
        "    else:\n",
        "        final_probs = probs\n",
        "    action_idx = int(np.random.choice(np.arange(len(final_probs)), p=final_probs))\n",
        "    action = ACTIONS[action_idx]\n",
        "    propensity = float(final_probs[action_idx])\n",
        "    return action, propensity, final_probs.tolist()\n",
        "\n",
        "# %% [markdown\n",
        "# ## 8. Chatbot Engine (Interactive)\n",
        "\n",
        "# %%\n",
        "def should_ask(field: FieldSpec, state: Dict[str, Any]) -> bool:\n",
        "    if field.depends_on is None:\n",
        "        return True\n",
        "    return bool(field.depends_on(state))\n",
        "\n",
        "def ask_field(field: FieldSpec, persona: str, state: Dict[str, Any], invalid_log: Dict[str,int]) -> Any:\n",
        "    base_prompt = field.prompt\n",
        "    while True:\n",
        "        user_input = input(style_prompt(base_prompt, persona) + \"\\n> \").strip()\n",
        "        # Basic sentiment from text\n",
        "        _, sentiment_score = analyze_sentiment(user_input)\n",
        "        turn_persona = detect_persona(\"neutral\", user_input, state)\n",
        "        ok, value, err = field.validator(user_input)\n",
        "        if ok:\n",
        "            return value, turn_persona\n",
        "        else:\n",
        "            invalid_log[field.name] = invalid_log.get(field.name, 0) + 1\n",
        "            print(style_error(f\"{err} Please try again.\", turn_persona))\n",
        "\n",
        "def chatbot_main():\n",
        "    print(\"Welcome to the Persona-Aware Loan Intake Bot.\\n\")\n",
        "    state: Dict[str, Any] = {}\n",
        "    persona = \"cooperative\"\n",
        "    invalid_log: Dict[str,int] = {}\n",
        "\n",
        "    for f in SCHEMA:\n",
        "        if not should_ask(f, state):\n",
        "            continue\n",
        "        value, persona = ask_field(f, persona, state, invalid_log)\n",
        "        state[f.name] = value\n",
        "\n",
        "    # --- Compute sentiment automatically ---\n",
        "    combined_text = \" \".join([str(state[f.name]) for f in SCHEMA if isinstance(state[f.name], str)])\n",
        "    sentiment_label, sentiment_score = analyze_sentiment(combined_text)\n",
        "    state[\"SentimentScore\"] = sentiment_score\n",
        "\n",
        "    # --- Predict target automatically ---\n",
        "    state[\"Target\"] = predict_target(state)\n",
        "    print(f\"\\nPredicted risk of missing next payment: {state['Target']:.2f}\")\n",
        "\n",
        "    # --- Detect persona ---\n",
        "    persona = detect_persona(sentiment_label, combined_text, state)\n",
        "    print(f\"Detected persona: {persona}\")\n",
        "\n",
        "    # --- Recommend strategy ---\n",
        "    strategy_probs = score_to_action_probs(state[\"Target\"], persona, state)\n",
        "    action, propensity, final_probs = sample_action(strategy_probs[\"probs\"])\n",
        "    print(f\"Recommended strategy: {action} (probability {propensity:.2f})\")\n",
        "\n",
        "    # --- Summary ---\n",
        "    print(\"\\nCollected Customer Data:\")\n",
        "    for k, v in state.items():\n",
        "        print(f\" - {k}: {v}\")\n",
        "\n",
        "    if invalid_log:\n",
        "        print(\"\\nFields with multiple retries:\")\n",
        "        for k, v in invalid_log.items():\n",
        "            if v > 0:\n",
        "                print(f\" - {k}: {v} retries\")\n",
        "\n",
        "# %% [markdown\n",
        "# ## 9. Run Chatbot\n",
        "\n",
        "# %%\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot_main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itI2DKmTHk35",
        "outputId": "a124b40c-9433-4404-ddf9-ccee2268231a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Welcome to the Persona-Aware Loan Intake Bot.\n",
            "\n",
            "friendly and informative: Enter your Customer ID (format: CUST0001, CUST0002, etc.):\n",
            "> CUST0003/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:__main__:Emotion analysis failed; returning neutral\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-1338900467.py\", line 7, in analyze_sentiment\n",
            "    sentiment = get_sentiment_pipeline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1099004905.py\", line 6, in get_sentiment_pipeline\n",
            "    _HF_PIPELINES[\"sentiment\"] = hf_pipeline(\n",
            "                                 ^^^^^^^^^^^\n",
            "NameError: name 'hf_pipeline' is not defined\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "informative: Customer ID must be in format 'CUST' followed by 4 digits, e.g., CUST0001. Please try again.\n",
            "friendly and informative: Enter your Customer ID (format: CUST0001, CUST0002, etc.):\n",
            "> CUST0001\n"
          ]
        }
      ]
    }
  ]
}